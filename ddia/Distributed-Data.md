# Part II. Distributed Data

Part I 이 데이터가 단일 노드에 저장될 때의 관점이라면, Part II는 여러 머신에서 일어나는 저장과 조회에 관한 것. 여러 머신에 데이터를 분산하려는 이유는 여러 가지가 있음.

- Scalability: 데이터 볼륨, 읽기 부하, 쓰기 부하가 커지면 하나의 머신으로는 다루기 어려움.
- Fault tolerance/high availabilty: 한 개의 장비가 고장나더라도 작업을 계속할 수 있는 가용성.
- Latency: 사용자가 전세계에 걸쳐 있다면, 지역적으로 가까운 데이터센터들을 제공할 수 있음.

## Scaling to Higher Load

### Shared-memory Architecture

- 더 많은 부하를 다루는 가장 쉬운 방법은 좀 더 강한 머신을 사는 것.
- 많은 CPU, RAM 칩, 디스크들은 하나의 OS에 묶일 수 있고,
- 서로 연결<sup>interconnect</sup>되어 CPU가 접근하게 할 수 있음.
- 문제점은 비용이 많이 증가한다는 것.
- 또한, 장애 내성이 높지 않다.

### Shared-disk Architecture

- 여러 머신들 사이에서 공유되는 디스크 배열에 데이터를 저장하는 것.
- 이들 디스크들은 빠른 네트워크로 연결됨.
- 데이터 웨어하우징 작업부하를 위해 사용되지만,
- 경합과 잠금 오버헤드는 확장성을 제한하는 요소가 됨.

### Shared-nothing Architectures

이 책에서는 이 접근법에 초점을 둠. 최선의 선택이어서가 아니라, 어플리케이션 개발자들이 신경써야 하는 것이 가장 많은 접근법이기 때문.

- 수평적 스케일링 또는 스케일링 아웃이라고 불리는 방법.
- DB 소프트웨어를 실행시키는 각 머신 또는 가상 머신은 노드<sup>node</sup>라고 부름.
- 각 노드는 자신의 CPU, RAM, 디스크를 독립적으로 사용.
- 노드 간의 조율은 소프트웨어 레벨에서 이뤄지고, 평범함 네트워크를 사용함.

### Replication Versus Partitioning

데이터가 여러 노드에 분산되는 방식에는 2가지가 존재. 이 둘은 별개의 메커니즘이지만, (당연하게도) 함께 사용될 수 있음.

**Replication**

- 서로 다른 위치에 있는 몇 개의 서로 다른 노드에 동일한 데이터의 복제본을 유지하는 것.
- 이는 redundancy를 제공함. 즉, 한 노드가 가용하지 않더라도, 다른 노드를 통해 데이터를 제공 받을 수 있음.
- 또한, 성능을 높여주기도.

**Partitioning**

- 큰 DB를 파티션이라고 불리는 몇 개의 부분집합으로 나누는 것.
- 이 부분집합은 서로 다른 노드에 할당됨.

# Replication

데이터 레플리케이션이란, 같은 데이터의 복제본을, 네트워크로 연결된 여러 머신에 유지하는 것. 레플리케이션의 이유는 여러 가지가 있음.

- 지역적으로 사용자에게 가까운 데이터를 제공하기 위해서.
- 일부가 고장나더라도 시스템은 계속 동작할 수 있게 하기 위해서.
- 읽기 전용 머신을 제공해서 읽기 성능을 높이기 위해서.

레플리케이션의 어려움은 복제된 데이터의 변경을 다루는 것에 있음. 노드간의 변경을 복제하는, 널리 알려진 3가지 알고리즘은 single-leader, multi-leader, leaderless(대부분의 분산 데이터베이스가 이 중 하나를 사용함).

레플리케이션 시 고려해야 하는 트레이드 오프는 다양함. 예컨대, 동기/비동기 복제, 실패한 레플리카를 어떻게 다룰 것인가 등.

## Leaders and Followers

DB의 복사본을 저장하는 각 노드를 가리켜 레플리카<sup>replica</sup>라고 부름. 여러 레플리카가 있다면, 아래 질문은 필수불가결.

> how do we ensure that all the data ends up on all the replicas?

DB에 대한 모든 쓰기는 모든 레플리카에서도 함께 처리되어야 함. 그렇지 않으면 같은 데이터를 가지고 있을 수 없음. 가장 흔한 해결책은 leader-based replication. 이는 active/passive 또는 master-slave replication이라고도 알려져 있음.

![](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0501.png)

1. 레플리카 중 하나가 리더로 지정됨. 클라이언트의 요청을 이 리더가 받게 됨.
2. 나머지 레플리카는 팔로워(read replicas, slaves, secondaries, hot standbys). 리더가 새로운 데이터를 저장할 때면, 이 변경사항을 레플리케이션 로그<sup>replication log</sup> 또는 변경 스트림<sup>change stream</sup>의 일부로써 모든 팔로워에게 전달함.
3. 읽기는 리더나 팔로워 중 누구에게나 할 수 있음. 하지만 쓰기는 리더에게만 이뤄져야 함.

많은 관계형 DB들이 이 기능을 기본으로 제공함. 또한, Kafka나 RabbitMQ와 같은 분산 메시지 브로커들도 제공. 네트워크 파일시스템이나 복제된 블럭 디바이스들도 이를 제공.

### Synchronous Versus Asynchronous Replication

아래 이미지는 동기 그리고 비동기 레플리케이션을 보여줌. 참고로, [PostgreSQL Replication Master Server Configuration](https://www.postgresql.org/docs/10/static/runtime-config-replication.html#RUNTIME-CONFIG-REPLICATION-MASTER)을 보면, 특정 노드만을 동기적 레플리케이션 대상으로 지정 가능함.

![](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0502.png)

**semi-synchronous**

동기로 할 경우 대부분 빠른 시간(1초 이내)에 레플리케이션이 끝나지만, 얼마나 더 걸릴 수도 있는지는 모르는 일. 예컨대, 팔로워 서버가 고장 나서 몇 분간 회복되고 있을 수도 있음. 그렇다고 모든 노드를 비동기로 하면, 리더 노드가 고장 났을 때, 최신 복제본을 가진 다른 노드가 있음을 보장하지 못함. 따라서, 1개의 팔로워만을 동기로 레플리케이션하는 것이 실용적. 최신 복제본을 가진 노드를 적어도 2개를 유지하면서, 팔로워들의 고장이 리더에게 미치는 영향을 최소화. 이를 가리켜 *semi-synchronous*라고 부름.

많은 리더 기반 레플리케이션이 완전한 비동기로 설정된다고 함. 내구성이 약해지는 문제<sup>weakining durability</sup>에도 불구. 특히, 팔로워가 많거나 지역적으로 분산된 경우에 더더욱.

데이터를 잃지 않으면서도 좋은 성능과 가용성을 보장하는 방법은 계속 연구중이고, chain replication은 그 결과물 중 하나. Microsoft Azure Storage 등에서 사용된다고 함.

### Setting Up New Followers

새로운 팔로워를 셋업해야 할 수 있음. 단순히 데이터를 복사하는 것으로는 충분치 않음. 데이터를 복사하는 중간에 리더 노드에 새로운 변경사항이 생길 수 있기 때문. 잠금을 사용하는 것은 가용성 측면에서 좋은 선택은 아님. 대신, 아래와 같이 해볼 수 있다.

1. 지속적으로 리더 DB의 스냅샷을 생성.
2. 새로운 팔로워 노드로 스냅샷을 복사.
3. 팔로워는 리더에게 특정 스냅샷 이후로 생긴 모든 데이터 변경을 요청. *log sequence number*(PostgreSQL) 또는 *binlog coordinates*(MySQL)라고 불리는 레플리케이션 로그의 정확한 위치를 알고 있어야 함.
4. 모든 변경을 다 따라잡았다면, 리더 노드로 투입.

위 절차는 DB마다 상당한 차이를 보일 수도 있음.

### Handling Node Outages

개별 노드가 고장나더라도 전체 시스템은 계속 동작하면서, 노드의 고장이 미치는 영향을 최소화하는 방법은 뭘까? 그러니까, 리더 기반 레플리케이션이 높은 가용성을 가지게 하려면 어떻게 해야 하는가?

#### Follower Failure: Catch-Up Recovery

팔로워 노드에 크래시가 일어나거나, 리더로부터의 네트워크가 단절되는 등의 문제가 있을 수 있음. 반영을 실패한 데이터 로그 지점부터 다시 반영을 시작하거나, 데이터 로그가 부족하다면 새로 추가된 데이터 로그를 리더로부터 받아오면 됨.

#### Leader Failure: Failover

페일오버<sup>failover</sup>는 까다로운 일. 보통 아래 절차를 밟음.

1. 리더가 고장났는지 여부를 판단.
   - 완전하게 고장을 파악할 수 있는 방법은 없으나,
   - 일반적으로 타임아웃을 사용.
2. 새로운 리더 선출.
   - 선거<sup>election</sup>(남아 있는 레플리카들에 의해 결정),
   - 또는 임명<sup>appoint</sup>(미리 지정된 컨트롤러 노드에 의해 결정)을 통해 선출됨.
   - 가장 좋은 후보는 가장 최신 데이터를 가진 레플리카.
3. 새로운 리더를 사용하도록 시스템 재설정.
   - 클라이언트는 새로운 리더에게 쓰기 요청을 보내야 함.
   - 만약, 오래된 리더가 다시 돌아오면, 시스템이 이를 팔로워라고 인식시켜 주어야 함.

페일오버는 다음과 같은 문제를 일으킬 수 있음.

- 비동기 레플리케이션이라면, 이전 리더의 데이터가 일부 유실될 수 있음. 가장 흔한 해결책(?)은 이 데이터를 버리는 것. 하지만, 이는 클라이언트의 내구성 기대를 위반.
- DB 데이터가 공유되는 또 다른 시스템이 있다면, 이러한 데이터 버림은 위험할 수 있음. [Github availability this week](https://blog.github.com/2012-09-14-github-availability-this-week/) 사례 참고.
- 두 개의 노드가 모두 스스로를 리더라고 생각하는 문제도 있음. 이렇게 되면 데이터가 유실되거나 충돌되기도 함. 이를 피하는 방법 중의 하나로, 두 개의 리더가 감지되면 하나를 중단시킴(단, 두 개의 노드가 모두 중단되는 위험도 있음).
- 리더가 죽었는지를 판별하는 타임아웃은 얼마가 적정한가? 긴 타임아웃은 복구하는 시간이 길다는 것을 의미. 반면, 너무 짧으면 (순간적인 부하 증가나 네트워크의 일시적 단절 등의 이유로) 불필요한 페일오버를 일으킬 수 있음.

어느 하나 쉬운 해결책이 없으며, 이런 이유로 어떤 운영팀은 수동 페일오버를 선호하기도 함. 노드 실패, 신뢰할 수 없는 네트워크, 레플리카 일관성에 대한 트레이드 오프, 내구성, 가용성, 응답 지연은 모두 분산 시스템이 가진 근본적 문제. 8장과 9장에서 이들을 좀 더 깊이 있게 다룰 예정.

### Implementation of Replication Logs

리더 기반 레플리케이션은 어떻게 동작하는가?

#### Statement-Based Replication

리더가 모든 쓰기 요청(명령문<sup>statement</sup>)을 로깅하고, 이를 팔로워들에게 보냄. 관계형 DB의 경우 `INSERT`, `DELETE` 등의 명령문이 여기에 해당. 가장 합리적인 선택으로 보이지만 아래와 같은 문제들이 발생할 수 있음.

- `NOW()`, `RAND()` 등의 비결정적 함수는 레플리카에서 다른 값을 만들어 냄.
- 명령문이 자동증가 컬럼을 사용하거나, `UPDATE ... WHERE ...`과 같이 존재하는 데이터에 의존하는 경우, 명령문은 레플리카에서 동일한 순서로 실행되어야 함. 이는 다수의 트랜잭션을 동시에 실행시키지 못하게 하는 제약.

이런 문제를 회피할 수 있긴 함. 에를 들어, 비결정적인 함수들의 호출을 고정된 명령문으로 치환해서 로그로 남길 수도 있음. 하지만 이외에도 여러 가지 엣지 케이스<sup>edge case</sup>들이 많아서 다른 방식들이 많이 사용됨. MySQL 5.1 이전 버전에서는 이 방식이 기본으로 사용되었음. 하지만, 현재는 로우 기반 레플리케이션이 기본값. VoltDB는 명령어 기반 레플리케이션을 사용하긴 하지만, 트랜잭션이 결정적이도록 요구.

#### Write-Ahead Log (WAL) Shipping

저장소 엔진은 모든 쓰기를 로그에 덧붙임. 로그 구조화 저장소 엔진은 이 방식이 기본이고, B 트리인 경우에도 이 WAL에 모든 변경이 가장 먼저 기록됨. 이 데이터를 레플리케이션 하는 것. 단점은 매우 저수준의 데이터라는 것. 즉, 레플리케이션이 특정 저장소와 강하게 결합됨. 버전 차이도 이런 문제를 만들 수 있음. 따라서, 다운 타임 없이는 버전 업그레이드가 불가.

#### Logical (Row-Based) Log Replication

한 가지 대안은 레플리케이션과 저장소를 위한 각각의 로그 포맷을 사용하는 것. 이를 가리켜 *logical log*라고 부름. 저장소 엔진의 물리적 데이터 표현과 구분하기 위함. 이 논리적 로그는 DB 테이블에 대한 쓰기를 표현하는 순차적 레코드.

- 삽입된 로우 − 모든 컬럼들에 대한 새로운 값을 로그가 포함함.
- 삭제된 로우 − 로우를 충분히 식별할 수 있을 정도의 정보를 가짐.
- 갱신된 로우 − 로우를 충분히 식별할 수 있을 정도의 정보와 모든 컬럼에 대한 새로운 값을 포함.

여러 행을 수정하는 트랜잭션은 이런 로그 레코드들을 여러 개 생성. 그리고 트랜잭션이 커밋되었음을 가리키는 레코드를 뒤이어 남김. [MySQL의 *binlog*](https://dev.mysql.com/doc/internals/en/binary-log-overview.html)는 이 접근법을 사용함.

저장소 엔진 내부와의 결합도가 낮기 때문에, 버전 차이는 물론이거니와 서로 다른 저장소 엔진 간에도 호환이 가능. 외부 애플리케이션이 파싱하는 것도 쉽다. 오프라인 분석을 위해 데이터 웨어하우스 같은 외부 시스템에 데이터를 보낼 때 유리. 종종 이를 가리켜 *change data capture*라고 부름.

#### Trigger-Based Replication

지금까지 살펴본 방식보다도 더 높은 유연성이 요구된다면, 애플리케이션 코드가 레플리케이션의 역할을 수행하게 할 수도 있음. 많은 관계형 데이터베이스에서는 *trigger* 그리고 *stored procedure*가 사용됨. *trigger*는 데이터 변경이 발생하면 등록된 커스텀 애플리케이션 코드를 자동으로 실행시켜줌. 레플리케이션에 바로 이 *trigger*를 사용할 수 있음. 하지만, 일반적으로 훨씬 더 큰 부하를 수반함. 버그도 많을 수 있고, 한계도 많음.


