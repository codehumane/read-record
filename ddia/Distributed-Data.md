# Part II. Distributed Data

Part I 이 데이터가 단일 노드에 저장될 때의 관점이라면, Part II는 여러 머신에서 일어나는 저장과 조회에 관한 것. 여러 머신에 데이터를 분산하려는 이유는 여러 가지가 있음.

- Scalability: 데이터 볼륨, 읽기 부하, 쓰기 부하가 커지면 하나의 머신으로는 다루기 어려움.
- Fault tolerance/high availabilty: 한 개의 장비가 고장나더라도 작업을 계속할 수 있는 가용성.
- Latency: 사용자가 전세계에 걸쳐 있다면, 지역적으로 가까운 데이터센터들을 제공할 수 있음.

## Scaling to Higher Load

### Shared-memory Architecture

- 더 많은 부하를 다루는 가장 쉬운 방법은 좀 더 강한 머신을 사는 것.
- 많은 CPU, RAM 칩, 디스크들은 하나의 OS에 묶일 수 있고,
- 서로 연결<sup>interconnect</sup>되어 CPU가 접근하게 할 수 있음.
- 문제점은 비용이 많이 증가한다는 것.
- 또한, 장애 내성이 높지 않다.

### Shared-disk Architecture

- 여러 머신들 사이에서 공유되는 디스크 배열에 데이터를 저장하는 것.
- 이들 디스크들은 빠른 네트워크로 연결됨.
- 데이터 웨어하우징 작업부하를 위해 사용되지만,
- 경합과 잠금 오버헤드는 확장성을 제한하는 요소가 됨.

### Shared-nothing Architectures

이 책에서는 이 접근법에 초점을 둠. 최선의 선택이어서가 아니라, 어플리케이션 개발자들이 신경써야 하는 것이 가장 많은 접근법이기 때문.

- 수평적 스케일링 또는 스케일링 아웃이라고 불리는 방법.
- DB 소프트웨어를 실행시키는 각 머신 또는 가상 머신은 노드<sup>node</sup>라고 부름.
- 각 노드는 자신의 CPU, RAM, 디스크를 독립적으로 사용.
- 노드 간의 조율은 소프트웨어 레벨에서 이뤄지고, 평범함 네트워크를 사용함.

### Replication Versus Partitioning

데이터가 여러 노드에 분산되는 방식에는 2가지가 존재. 이 둘은 별개의 메커니즘이지만, (당연하게도) 함께 사용될 수 있음.

**Replication**

- 서로 다른 위치에 있는 몇 개의 서로 다른 노드에 동일한 데이터의 복제본을 유지하는 것.
- 이는 redundancy를 제공함. 즉, 한 노드가 가용하지 않더라도, 다른 노드를 통해 데이터를 제공 받을 수 있음.
- 또한, 성능을 높여주기도.

**Partitioning**

- 큰 DB를 파티션이라고 불리는 몇 개의 부분집합으로 나누는 것.
- 이 부분집합은 서로 다른 노드에 할당됨.

# Replication

데이터 레플리케이션이란, 같은 데이터의 복제본을, 네트워크로 연결된 여러 머신에 유지하는 것. 레플리케이션의 이유는 여러 가지가 있음.

- 지역적으로 사용자에게 가까운 데이터를 제공하기 위해서.
- 일부가 고장나더라도 시스템은 계속 동작할 수 있게 하기 위해서.
- 읽기 전용 머신을 제공해서 읽기 성능을 높이기 위해서.

레플리케이션의 어려움은 복제된 데이터의 변경을 다루는 것에 있음. 노드간의 변경을 복제하는, 널리 알려진 3가지 알고리즘은 single-leader, multi-leader, leaderless(대부분의 분산 데이터베이스가 이 중 하나를 사용함).

레플리케이션 시 고려해야 하는 트레이드 오프는 다양함. 예컨대, 동기/비동기 복제, 실패한 레플리카를 어떻게 다룰 것인가 등.

## Leaders and Followers

DB의 복사본을 저장하는 각 노드를 가리켜 레플리카<sup>replica</sup>라고 부름. 여러 레플리카가 있다면, 아래 질문은 필수불가결.

> how do we ensure that all the data ends up on all the replicas?

DB에 대한 모든 쓰기는 모든 레플리카에서도 함께 처리되어야 함. 그렇지 않으면 같은 데이터를 가지고 있을 수 없음. 가장 흔한 해결책은 leader-based replication. 이는 active/passive 또는 master-slave replication이라고도 알려져 있음.

![](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0501.png)

1. 레플리카 중 하나가 리더로 지정됨. 클라이언트의 요청을 이 리더가 받게 됨.
2. 나머지 레플리카는 팔로워(read replicas, slaves, secondaries, hot standbys). 리더가 새로운 데이터를 저장할 때면, 이 변경사항을 레플리케이션 로그<sup>replication log</sup> 또는 변경 스트림<sup>change stream</sup>의 일부로써 모든 팔로워에게 전달함.
3. 읽기는 리더나 팔로워 중 누구에게나 할 수 있음. 하지만 쓰기는 리더에게만 이뤄져야 함.

많은 관계형 DB들이 이 기능을 기본으로 제공함. 또한, Kafka나 RabbitMQ와 같은 분산 메시지 브로커들도 제공. 네트워크 파일시스템이나 복제된 블럭 디바이스들도 이를 제공.

### Synchronous Versus Asynchronous Replication

아래 이미지는 동기 그리고 비동기 레플리케이션을 보여줌. 참고로, [PostgreSQL Replication Master Server Configuration](https://www.postgresql.org/docs/10/static/runtime-config-replication.html#RUNTIME-CONFIG-REPLICATION-MASTER)을 보면, 특정 노드만을 동기적 레플리케이션 대상으로 지정 가능함.

![](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0502.png)

**semi-synchronous**

동기로 할 경우 대부분 빠른 시간(1초 이내)에 레플리케이션이 끝나지만, 얼마나 더 걸릴 수도 있는지는 모르는 일. 예컨대, 팔로워 서버가 고장 나서 몇 분간 회복되고 있을 수도 있음. 그렇다고 모든 노드를 비동기로 하면, 리더 노드가 고장 났을 때, 최신 복제본을 가진 다른 노드가 있음을 보장하지 못함. 따라서, 1개의 팔로워만을 동기로 레플리케이션하는 것이 실용적. 최신 복제본을 가진 노드를 적어도 2개를 유지하면서, 팔로워들의 고장이 리더에게 미치는 영향을 최소화. 이를 가리켜 *semi-synchronous*라고 부름.

많은 리더 기반 레플리케이션이 완전한 비동기로 설정된다고 함. 내구성이 약해지는 문제<sup>weakining durability</sup>에도 불구. 특히, 팔로워가 많거나 지역적으로 분산된 경우에 더더욱.

데이터를 잃지 않으면서도 좋은 성능과 가용성을 보장하는 방법은 계속 연구중이고, chain replication은 그 결과물 중 하나. Microsoft Azure Storage 등에서 사용된다고 함.

### Setting Up New Followers

새로운 팔로워를 셋업해야 할 수 있음. 단순히 데이터를 복사하는 것으로는 충분치 않음. 데이터를 복사하는 중간에 리더 노드에 새로운 변경사항이 생길 수 있기 때문. 잠금을 사용하는 것은 가용성 측면에서 좋은 선택은 아님. 대신, 아래와 같이 해볼 수 있다.

1. 지속적으로 리더 DB의 스냅샷을 생성.
2. 새로운 팔로워 노드로 스냅샷을 복사.
3. 팔로워는 리더에게 특정 스냅샷 이후로 생긴 모든 데이터 변경을 요청. *log sequence number*(PostgreSQL) 또는 *binlog coordinates*(MySQL)라고 불리는 레플리케이션 로그의 정확한 위치를 알고 있어야 함.
4. 모든 변경을 다 따라잡았다면, 리더 노드로 투입.

위 절차는 DB마다 상당한 차이를 보일 수도 있음.

### Handling Node Outages

개별 노드가 고장나더라도 전체 시스템은 계속 동작하면서, 노드의 고장이 미치는 영향을 최소화하는 방법은 뭘까? 그러니까, 리더 기반 레플리케이션이 높은 가용성을 가지게 하려면 어떻게 해야 하는가?

#### Follower Failure: Catch-Up Recovery

팔로워 노드에 크래시가 일어나거나, 리더로부터의 네트워크가 단절되는 등의 문제가 있을 수 있음. 반영을 실패한 데이터 로그 지점부터 다시 반영을 시작하거나, 데이터 로그가 부족하다면 새로 추가된 데이터 로그를 리더로부터 받아오면 됨.

#### Leader Failure: Failover

페일오버<sup>failover</sup>는 까다로운 일. 보통 아래 절차를 밟음.

1. 리더가 고장났는지 여부를 판단.
   - 완전하게 고장을 파악할 수 있는 방법은 없으나,
   - 일반적으로 타임아웃을 사용.
2. 새로운 리더 선출.
   - 선거<sup>election</sup>(남아 있는 레플리카들에 의해 결정),
   - 또는 임명<sup>appoint</sup>(미리 지정된 컨트롤러 노드에 의해 결정)을 통해 선출됨.
   - 가장 좋은 후보는 가장 최신 데이터를 가진 레플리카.
3. 새로운 리더를 사용하도록 시스템 재설정.
   - 클라이언트는 새로운 리더에게 쓰기 요청을 보내야 함.
   - 만약, 오래된 리더가 다시 돌아오면, 시스템이 이를 팔로워라고 인식시켜 주어야 함.

페일오버는 다음과 같은 문제를 일으킬 수 있음.

- 비동기 레플리케이션이라면, 이전 리더의 데이터가 일부 유실될 수 있음. 가장 흔한 해결책(?)은 이 데이터를 버리는 것. 하지만, 이는 클라이언트의 내구성 기대를 위반.
- DB 데이터가 공유되는 또 다른 시스템이 있다면, 이러한 데이터 버림은 위험할 수 있음. [Github availability this week](https://blog.github.com/2012-09-14-github-availability-this-week/) 사례 참고.
- 두 개의 노드가 모두 스스로를 리더라고 생각하는 문제도 있음. 이렇게 되면 데이터가 유실되거나 충돌되기도 함. 이를 피하는 방법 중의 하나로, 두 개의 리더가 감지되면 하나를 중단시킴(단, 두 개의 노드가 모두 중단되는 위험도 있음).
- 리더가 죽었는지를 판별하는 타임아웃은 얼마가 적정한가? 긴 타임아웃은 복구하는 시간이 길다는 것을 의미. 반면, 너무 짧으면 (순간적인 부하 증가나 네트워크의 일시적 단절 등의 이유로) 불필요한 페일오버를 일으킬 수 있음.

어느 하나 쉬운 해결책이 없으며, 이런 이유로 어떤 운영팀은 수동 페일오버를 선호하기도 함. 노드 실패, 신뢰할 수 없는 네트워크, 레플리카 일관성에 대한 트레이드 오프, 내구성, 가용성, 응답 지연은 모두 분산 시스템이 가진 근본적 문제. 8장과 9장에서 이들을 좀 더 깊이 있게 다룰 예정.

### Implementation of Replication Logs

리더 기반 레플리케이션은 어떻게 동작하는가?

#### Statement-Based Replication

리더가 모든 쓰기 요청(명령문<sup>statement</sup>)을 로깅하고, 이를 팔로워들에게 보냄. 관계형 DB의 경우 `INSERT`, `DELETE` 등의 명령문이 여기에 해당. 가장 합리적인 선택으로 보이지만 아래와 같은 문제들이 발생할 수 있음.

- `NOW()`, `RAND()` 등의 비결정적 함수는 레플리카에서 다른 값을 만들어 냄.
- 명령문이 자동증가 컬럼을 사용하거나, `UPDATE ... WHERE ...`과 같이 존재하는 데이터에 의존하는 경우, 명령문은 레플리카에서 동일한 순서로 실행되어야 함. 이는 복수의 트랜잭션을 동시에 실행시키지 못하게 하는 제약.

이런 문제를 회피할 수 있긴 함. 에를 들어, 비결정적인 함수들의 호출을 고정된 명령문으로 치환해서 로그로 남길 수도 있음. 하지만 이외에도 여러 가지 엣지 케이스<sup>edge case</sup>들이 많아서 다른 방식들이 많이 사용됨. MySQL 5.1 이전 버전에서는 이 방식이 기본으로 사용되었음. 하지만, 현재는 로우 기반 레플리케이션이 기본값. VoltDB는 명령어 기반 레플리케이션을 사용하긴 하지만, 트랜잭션이 결정적이도록 요구.

#### Write-Ahead Log (WAL) Shipping

저장소 엔진은 모든 쓰기를 로그에 덧붙임. 로그 구조화 저장소 엔진은 이 방식이 기본이고, B 트리인 경우에도 이 WAL에 모든 변경이 가장 먼저 기록됨. 이 데이터를 레플리케이션 하는 것. 단점은 매우 저수준의 데이터라는 것. 즉, 레플리케이션이 특정 저장소와 강하게 결합됨. 버전 차이도 이런 문제를 만들 수 있음. 따라서, 다운 타임 없이는 버전 업그레이드가 불가.

#### Logical (Row-Based) Log Replication

한 가지 대안은 레플리케이션과 저장소를 위한 각각의 로그 포맷을 사용하는 것. 이를 가리켜 *logical log*라고 부름. 저장소 엔진의 물리적 데이터 표현과 구분하기 위함. 이 논리적 로그는 DB 테이블에 대한 쓰기를 표현하는 순차적 레코드.

- 삽입된 로우 − 모든 컬럼들에 대한 새로운 값을 로그가 포함함.
- 삭제된 로우 − 로우를 충분히 식별할 수 있을 정도의 정보를 가짐.
- 갱신된 로우 − 로우를 충분히 식별할 수 있을 정도의 정보와 모든 컬럼에 대한 새로운 값을 포함.

여러 행을 수정하는 트랜잭션은 이런 로그 레코드들을 여러 개 생성. 그리고 트랜잭션이 커밋되었음을 가리키는 레코드를 뒤이어 남김. [MySQL의 *binlog*](https://dev.mysql.com/doc/internals/en/binary-log-overview.html)는 이 접근법을 사용함.

저장소 엔진 내부와의 결합도가 낮기 때문에, 버전 차이는 물론이거니와 서로 다른 저장소 엔진 간에도 호환이 가능. 외부 애플리케이션이 파싱하는 것도 쉽다. 오프라인 분석을 위해 데이터 웨어하우스 같은 외부 시스템에 데이터를 보낼 때 유리. 종종 이를 가리켜 *change data capture*라고 부름.

#### Trigger-Based Replication

지금까지 살펴본 방식보다도 더 높은 유연성이 요구된다면, 애플리케이션 코드가 레플리케이션의 역할을 수행하게 할 수도 있음. 많은 관계형 데이터베이스에서는 *trigger* 그리고 *stored procedure*가 사용됨. *trigger*는 데이터 변경이 발생하면 등록된 커스텀 애플리케이션 코드를 자동으로 실행시켜줌. 레플리케이션에 바로 이 *trigger*를 사용할 수 있음. 하지만, 일반적으로 훨씬 더 큰 부하를 수반함. 버그도 많을 수 있고, 한계도 많음.

## Problems with Replication Lag

앞서 계속 설명된 것 처럼, 레플리케이션의 이유는 아래와 같음.

1. fault tolerance (한 머신이 고장나도 다른 머신이 작업을 대체)
2. scalability (하나의 머신에서 다룰 수 있는 것 보다 큰 요청을 처리)
3. latency (사용자에게 지역적으로 가까운 곳에 레플리카를 위치)

이를 위해 여러 팔로워를 추가할 수 있으며, 이 때는 레플리케이션을 동기로 할지 비동기로 할지 선택해야 함.

1. synchronous − 팔로워 중 하나라도 문제 있는 경우 쓰기가 동작할 수 없음. 팔로워가 늘어날 수록 이 문제의 가능성은 커짐.
2. asnychronous − 팔로워 노드에서 최신 데이터를 제공함을 보장하지 못함. 이러한 비일관성은 일시적이긴 함. 결과적 일관성<sup>eventual consistency</sup>.

참고로, "eventually"라는 용어는 의도적으로 모호함을 가짐. 그러니까, 레플리케이션 지연<sup>replication lag</sup>이 얼마나 될지에 대한 일반적인 제약이 없다는 의미. 네트워크 상황이나 가용한 OS 리소스 상태에 따라 수초에서 수분까지 걸릴 수도.

동기 옵션은 사용 X. 최대 1대까지만을 동기로 고려. 뒤이어 다루는 내용도 모두 비동기를 사용하는 것을 전제로 하고 있음.

### Reading Your Own Writes

아래 그림은 쓰기 데이터가 바로 보이지 않을 수도 있는 비일관성을 나타냄.

![](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0503.png)

이를 해결하기 위해 *read-after-write consistency*(혹은 *read-your-writes consistency*)가 필요함. 사용자가 스스로가 만든 변경 사항은 항상 최신으로 보여주는 것. 구현하는 방법은 몇 가지가 있다.

- 자신이 수정할 수 있는 대상은 리더로부터 불러들임. 예컨대, A라는 사용자가 접속한 경우, A의 프로필은 리더로부터 가져오고, 그 외의 것은 팔로워로부터 가져옴.
- 하지만, 데이터가 여러 사용자에 의해 수정될 수 있다면 위 접근법은 비효과적. 대부분 리더로부터 가져오게 될 테니까. 대신, 마지막 갱신 시간을 추적해서, 갱신된 지 1분 이내라면 리더로부터 데이터를 가져올 수도 있음.
- 마지막으로 갱신이 일어난 타임스탬프까지 팔로워들이 따라잡도록 할 수도 있음. 만약, 어떤 레플리카가 충분히 최신이 아니라면, 다른 레플리카로 리드 요청을 처리하거나, 레플리카가 충분히 따라잡을 때까지 요청을 대기. 참고로, 이때의 타임스탬프는 논리적 타임스탬프<sup>logical timestamp</sup>(쓰기 순서 등)일 수 있음.

데이터센터가 지역적으로 분산되어 있는 경우에는 이 복잡성이 더 커짐. 또한, 같은 사용자가 여러 디바이스를 통해 접근하는 경우에도 복잡성은 높아진다.

### Monotonic Reads

같은 리드 요청이 여러 팔로워들에 분산될 때도 비일관성 문제가 발생함.

![](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0504.png)

Monotonic reads는 한 가지 해결책. 최신 데이터를 보지는 못할 수도 있지만, 한 번 읽어 들인 시점보다 과거의 데이터를 제공하지는 않는 것. 강한 일관성<sup>strong consistency</sup> 보다는 약하고, 결과적 일관성<sup>eventual consistency</sup> 보다는 강한 보장.

이를 달성하는 한 가지 방법은 각 사용자는 항상 같은 레플리카를 보게 하는 것. 예컨대, 사용자 ID의 해시(랜돔이 아니고)에 기반하여 레플리카를 선택하게 함. 그리고 만약 대상 레플리카가 장애가 났다면, 다른 레플리카로 재 라우팅.

### Consistent Prefix Reads

A, B가 순서대로 발생했지만, 레플리케이션 지연에 의해 B, A 순서로 이벤트가 발생한 것 처럼 보이는 현상. 이 문제는 파티션 된(혹은 샤드가 된) 데이터베이스의 특수한 문제라고 함. 쓰기 순서를 전역적으로 보장할 수 있는 방법이 없기 때문.

![](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0505.png)

Consistent prefix reads는 한 가지 해결책. 쓰기가 발생한 순서대로 데이터를 읽게 하는 것. 이를 위해, 관련 있는 데이터는 같은 파티션에 둘 수도 있음. 하지만 일부 애플리케이션에서는 이를 효율적으로 수행하기가 어려움. 이런 인과적 의존성을 추적할 수 있는 알고리즘도 있음. 뒤에서 다룰 예정.

### Solutions for Replication Lag

- "레플리케이션 지연이 증가되면 애플리케이션에 문제가 있을까?"를 먼저 질문.
- 아무런 문제도 없다고 할 수도 있음. 그러면 끝.
- 문제가 있다면, 위에서 살펴 본 좀 더 강한 보장을 시스템에서 제공.
- 하지만, 이는 애플리케이션 코드의 복잡성을 높이고 잘못되기도 쉽다.
- 그런 면에서는 개발자가 이 문제에 신경을 안 쓰게 하는 것이 가장 좋아 보임.
- 단일 노드에서 트랜잭션이 존재하는 이유이기도 함.
- 하지만, 분산된 시스템에서는 이러한 보장이 되지 않음. 성능과 가용성 측면에서 너무 비싸다며 오히려 포기한 상태.
- 대신, 결과적 일관성이 확장 가능한 시스템에서는 필수 불가결이라고 주장.
- 어느 정도는 사실이지만, 책의 나머지 부분에 대해서는 조금씩 다른 관점들을 다룰 예정.

## Multi-Leader Replication

지금까지 리더 기반 레플리케이션 모델에 대해서 알아봄. 이번에는 다중 리더<sup>multi-leader</sup>(master-master 또는 active/active) 레플리케이션에 대해서 살펴볼 예정. 리더가 하나이면 이 리더가 문제가 있을 경우 쓰기가 불가. 리더가 복수이면 이 문제를 어느 정도 극복. 이 리더들은 기본적으로 리더처럼 동작하지만, 다른 리더에 대해서는 팔로워처럼 동작함.

### Use Cases for Multi-Leader Replication

하나의 데이터센터에서 다중 리더 설정을 하는 것을 일반적으로 비합리적. 복잡성이 너무 높기 때문. 하지만, 몇 가지 이득이 되는 경우가 있음.

#### Multi-Datacenter Operation

각 데이터 센터에 한 개의 리더를 두는 것. 그림은 [여기](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0506.png) 참고. 리더에 사용자의 쓰기 요청이 들어오면, 이를 우선 자신의 데이터 센터에 있는 레플리카로 보내고, 동시에 다른 데이터 센터에 있는 *confilict resoultion*에게도 전달함. 충돌 문제가 없다면 그 데이터 센터의 리더에게 전달.

아래는 데이터 센터가 여러 개일 때 단일 리더와 복수 리더 설정의 차이.

*Performance*

- 읽기의 차이는 없을 것.
- 단일 리더 − A 데이터 센터에 가까운 쓰기 요청이, 리더가 있는 B 데이터 센터에 먼저 전달되고, 다시 A 데이터 센터로 레플리케이션 되는 시간적 비용은 상당함.
- 복수 리더 − 쓰기 요청은 각 지역의 데이터 센터로 보내지므로, 단일 리더에 비해 성능은 좋음.

Tolerance of datacenter outages

- 단일 리더 − 리더가 있던 데이터 센터에 장애가 나면, 다른 데이터 센터의 한 팔로워를 리더로 승격시켜야 함.
- 복수 리더 − 단일 리더에서의 절차가 필요 없음. 그냥 계속 운영하면 됨.

*Tolerance of network problem*

- 데이터 센터 간의 네트워크는 주로 퍼블릭. 이는 로컬 네트워크에 비해 낮은 신뢰성을 가짐.
- 단일 리더 − 쓰기 요청이 이 퍼블릭 링크를 통해 동기적으로 이뤄지므로 신뢰성이 낮을 수 있음.
- 복수 리더 − 비동기적으로 레플리케이션이 이뤄짐. 일시적 네트워크 문제는 견뎌낼 수 있음.

일부 데이터베이스는 복수 리더 설정을 기본으로 제공함. 또는 MySQL에는 Tungsten, PosgtreSQL에는 BDR, Oracle에는 GoldenGate 등 외부 도구들도 존재.

#### Clients With Offline Operation

애플리케이션이 인터넷으로부터 연결이 끊겼음에도 동작해야 할 필요가 있을 때, 복수 리더 레플리케이션을 사용할 수 있다고 함. 하지만, 중간의 내용을 보면, "데이터센터 간의 네트워크 연결이 신뢰하기 어려운 상황에서"라고 되어 있음. 개인적으로는 이 표현이 올바르다고 생각함.

일정 시간 네트워크가 동작하지 않을 수 있고, 이로 인해 얼마 간의 데이터를 동기화해야 하는 작업이 필요한데, 이 작업이 만만한 것은 아님. 이런 설정을 쉽게 할 수 있도록 도와주는 도구들이 있음. 예컨대, CouchDB는 이런 운영 모드를 위해 설계되었다고 함.

#### Collaborative Editing

복수의 사용자가 동시에 하나의 문서를 편집하는 것과 데이터베이스 레플리케이션은 비슷한 점이 많음. 오프라인 편집 사용 사례도 같은 맥락. 큰 단위(e.g 문서)의 락 대신, 작은 단위(e.g 단일 키스트로크)를 유지하고, 충돌 해결 전략을 함께 제공.

### Handling Writes Conflicts

복수 리더 레플리케이션의 최대 문제. 쓰기 충돌. 표로 나타내면 다음과 같음.

| A 데이터센터 마스터                              | B 데이터센터 마스터                          |
| ------------------------------------------------ | -------------------------------------------- |
| `insert into user (id, name) values (1, 'foo');` |                                              |
|                                                  | A로부터 레코드 `1`이 레플리케이션 됨         |
|                                                  | `update user set name = 'bar' where id = 1;` |
| `update user set name = 'baz' where id = 1;`     |                                              |
| B로부터 레코드 `1`이 레플리케이션 된다면?        |                                              |

*"Q. B로부터 레코드 `1`이 레플리케이션 된다면, `name`은 `bar`인가 `baz`인가?"*

단일 리더 데이터베이스에서는, 첫 번째 쓰기가 완료될 때 까지, 두 번째 작성자를 대기시킬 수 있음. 혹은, 두 번째 작성자에게 재시도를 안내하면서 진행중이던 트랜잭션을 종료시킬 수도. 반면, 복수 리더 설정에서는, 두 개의 쓰기가 모두 성공함. 충돌은 일정 시간이 지난 뒤 비동기적으로 감지될 뿐. 사용자에게 충돌 해결을 요구하기에는 너무 늦어버렸을 수도.

#### Synchronous Versus Asynchronous Conflict Detection

특정 리더에 쓰기 요청이 들어오면, 다른 데이터센터의 리더에 레플리케이션 될 때까지 쓰기 완료를 대기시킬 수 있음. 그러나 위에서 이야기한 것처럼, 네트워크 상황에 따라 쓰기의 신뢰성이 낮아질 수 있음. 책에서는 권장하지 않는 방식.

#### Conflict Avoidance

아예 충돌을 회피하는 방법을 취할 수도 있음. 예를 들어, 레코드 별로 쓰기가 가능한 리더를 할당하고, 같은 리더만 접근을 허용. 복수 리더 레플리케이션의 충돌을 다루는 많은 구현들이 부실하기 때문에 자주 사용되는 접근 방식.

하지만, 레코드에 할당된 리더를 변경해야 할 수도. 특정 데이터 센터에 장애가 발생했거나, 사용자가 다른 지역으로 이동하는 바람에 지역적으로 가까운 데이터 센터가 바뀌었다던가 하는 등의 이유로 말이다. 충돌 회피가 깨질 수도 있는 것. 하지만 개인적으로는 충돌 회피가 왜 깨지는지 이해X. 라우팅 설정을 바꾸는 사이에 쓰기 요청이 들어오는 경우를 말하는 건가?

#### Converging Toward a Consistent State

단일 리더 데이터베이스에서는 쓰기가 순서대로 이뤄짐. 같은 필드에 여러 번의 갱신이 있다면, 마지막 쓰기가 그 필드의 마지막 값임. 하지만, 복수 리더 설정에서는 쓰기의 순서가 정의되지 않음. A 데이터 센터에는 1이라는 값이, B 데이터 센터에는 2라는 값이 있는 상태에서, 어떻게 결과적으로 모든 레플리카가 같은 값을 가지도록 보장할 수 있을까?

수렴 충돌 해결<sup>convergent conflict resolution</sup>을 해결하는 방법에는 여러 가지가 있음.

- 각 쓰기에 고유 ID(e.g 타임스탬프, 긴 랜덤 숫자, UUID, 키와 값의 해시)를 부여. 가장 높은 ID를 가진 쓰기가 승자. 나머지는 모두 버림. 타임스탬프가 사용되었다면, 이런 기법을 가리켜 LWW(Last Write Wins)라고 함. 이 방법이 널리 퍼져 있긴 하지만, 데이터 유실이 발생할 수 있음.
- 각 레플리카에 고유 ID를 부여. 그리고 쓰기를 수행할 레플리카를 선택할 때, 가장 높은 숫자가 부여된 노드를 선택. 이 또한 데이터 유실 가능성 내포.
- 어떻게든 값을 병합. 예컨대, 1과 3이라는 값이 각 리더에 있다면, 1/3이라는 값으로 만듦.
- 명시적인 데이터 구조에 충돌을 기록하고, 어플리케이션에서 이를 해결하도록 함. 사용자에게 충돌 해결을 위임할 수도.

#### Custom Conflict Resolution Logic

올바른 충돌 해결은 애플리케이션에 따라 다르므로, 대부분의 복수 리더 레플리케이션 도구들은 애플리케이션 코드를 통해 충돌 해결 로직을 작성할 수 있게 함. 이 코드는 쓰기 또는 읽기 시점에 수행.

##### 쓰기 시점

- 레플리케이션 된 변경 로그에서 충돌이 감지되는 즉시 충돌 핸들러 호출.
- 백그라운드 프로세스로 빠르게 처리됨.
- 따라서, 사용자에게는 안내 되지 않는 것이 일반적.

##### 읽기 시점

- 충돌 나는 쓰기라고 해도 일단 저장.
- 이 충돌 데이터에 대한 읽기가 발생하면, 데이터의 여러 버전을 애플리케이션에 반환.
- 애플리케이션에서는 이를 직접 해결하고 그 결과를 데이터베이스로 보내줄 수도 있고,
- 충돌을 사용자에게 안내하여 해결을 유도할 수도 있음.

참고로, 충돌 해결의 단위는 전체 트랜잭션이 아니라, 개별 로우 또는 도큐먼트에 대해 이뤄지는 것이 일반적.

### Multi-Leader Replication Topologies

레플리케이션 토폴로지<sup>replication topologiy</sup>는 노드 간에 쓰기 레플리케이션이 이뤄지는 커뮤니케이션 경로를 표현. circular topology, start topology, all-to-all topology가 그 예. [여기 그림](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0508.png) 함께 참고.

- 가장 일반적인 토폴로지는 all-to-all.
- MySQL은 circular 만을 기본으로 지원.
- circular 그리고 star 토폴로지는 쓰기가 몇 개의 노드를 거쳐가기도. 이 때 발생할 수 있는 무한 루프를 방지하기 위해, 각 노드는 고유 식별자를 가지고 있으며, 이 식별자를 각 쓰기에 태깅함.
- circular 그리고 star 토폴로지는 한 노드에 장애가 생기면, 경로가 끊어지게 되고, 따라서 재설정 되어야 함.
- All-to-all에서도 문제가 있음. 바로 "추월<sup>overtake</sup>". [그림](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0509.png) 참고.
- 이런 순서 이슈를 해결하기 위해 버전 벡터<sup>version vectors</sup> 같은 것이 사용되기도 함(뒤이어 다뤄지는 내용). 하지만, 충돌 감지 기술은 많은 시스템에서 부실하게 구현되어 있다는 것에 주의.

## Leaderless Replication

'Sloppy Quorums and Hinted Handoff'에서 리더 없는 레플리케이션을 잘 정리하는 문단이 있어서 함께 기록.

> Databases with appropriately configured quorums can tolerate the failure of indivisual nodes without the need for failover. They can also tolerate individual nodes going slow, because requests don't have to wait for all n nodes to respond―they can return when w or r nodes have responded. These characteristics make databases with leaderless replication applealing for use cases that require high availability and low latency, and that can tolerate occasional stale reads.

관계형 데이터베이스 시대 동안 리더 없는 레플리케이션은 잊혀짐. 그러다가 Amazon이 인하우스 Dynamo 시스템에 이 모델을 사용하면서 점점 다른 곳에서도 사용. Riak, Cassandra, Voldemort가 그 예. 이 때문에 이 모델을 가리켜 Dynamo-style이라고도 부름.

이 모델에서는 클라이언트가 특정 노드가 아닌 임의의 레플리카로 쓰기 요청을 보냄. 또는, 코디네이터 노드가 이 역할을 대신 수행하거나.

### Writing to the Database When a node Is Down

리더 없는 레플리케이션은 노드의 장애복구<sup>failover</sup>가 필요 없음. 대신, 아래와 같은 방식으로 쓰기와 읽기 요청을 처리함. [여기 그림](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0510.png) 함께 참고.

- 클라이언트는 쓰기 요청을 모든 레플리카에게 병렬로 보냄.
- 이 중 한 노드가 업데이트로 인해 중단 되었다고 가정.
- 그러면, 클라이언트는 나머지 정상 노드로부터만 응답을 받음.
- 그러다가 중단 되었던 노드가 다시 클러스터로 복귀.
- 클라이언트는 읽기를 위해 모든 레플리카에게 병렬로 요청을 보냄.
- 중단 되었던 노드로부터는 오래된<sup>stale</sup> 데이터를 받을 수 있음.
- 클라이언트는 버전 번호를 통해 어떤 값이 최신인지를 스스로 판단.

#### Read Repair And Anti-Entropy

문제가 되던 노드가 정상화 되면, 이 노드는 최신 쓰기를 어떻게 따라잡을까? read repiar 그리고 anti-entropy process 이렇게 두 가지 방법이 주로 사용된다고 함.

먼저, read repair.

- 클라이언트가 읽기 요청을 여러 노드에 동시에 날렸다면,
- 최신 데이터와 오래된 데이터를 감지할 수 있으며,
- 오래된 데이터를 반환한 노드에게 최신 데이터를 보내 쓰기 요청.
- 자주 읽히는 값일 때 잘 동작한다고 함.

다음으로, anti-entropy process.

- 백그라운드 프로세스가 있고,
- 레플리카 간의 데이터 차이를 찾아다니다가,
- 누락된 데이터가 있으면 이를 복제함.
- 리더 기반 레플리케이션에서의 레플리케이션 로그와 다르게,
- 쓰기를 순서대로 복제하지 않음.
- 따라서, 데이터가 복제가 심각할 정도로 지연될 수도 있음.

위에서 언급했던, 코디네이터 노드가 없다면 read repair 방식은 애플리케이션 입장에서는 너무 부담. anti-entropy process 방식이 더 낫지 않을까 함. 데이터 복제가 심각할 정도로 지연된다는 것은 무엇일까. 레플리카가 많을 수록 데이터 복제의 지연은 문제가 될 가능성은 낮아 보임. 하지만, 데이터 크기가 많아질 수록 문제가 될 수도 있을 것 같기도 하고. 그렇다고, 이를 보완하는 방법이 아예 없을 것 같지도 않고. 여러모로 추가 확인이 필요해 보임.

#### Quorums for Reading And Writing

- 전체 노드의 갯수가 `n`,
- 쓰기가 가능한 노드의 갯수를 `w`,
- 읽기가 가능한 노드의 갯수를 `r`이라고 할 때,
- `w + r > n`을 만족시켜야 한다고 함.
- 일반적으로 `n`은 홀수로 두고, `w = r = (n + 1) / 2 (반올림)`을 만족시켜야 함.
- [여기 그림](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0511.png)처럼, 적어도 하나의 노드로부터 최신 데이터를 읽어 들일 수 있기 때문.
- 여기서 중요한 건, `w`와 `r`은 얼마나 많은 노드로부터 응답을 기다려야 하는지를 결정하는 값이라는 것.
- 응답이 돌아오지 않는 이유는 다양. 노드가 중단되었을 수도 있고, 디스크 부족 등의 이유로 연산을 못 해서 그럴 수도 있고, 네트워크 단절이 있을 수도 있고. 어쨌든 중요한 건 몇 개의 노드로부터 응답을 받았는가.

### Limitations of Quorum Consistency

좀 더 유연한 설정도 가능함.

- `w + r ≦ n` 값을 설정할 수도 있음.
- 오래된 값을 읽어 들일 가능성은 높아짐.
- 하지만, 응답 지연이 낮고 가용성은 높아짐.

참고로, `w + r > n`에서도 오래된 값이 나올 가능성이 있음. 책에서는 몇 가지 시나리오를 언급하지만, 잘 이해되지 않아 기록하지는 않음. 추후 다시 살펴볼 것. 어쨌든 실제로는 쿼럼 수가 항상 최신 값 읽기를 보장하지는 못한다는 것. Dynamo 스타일 데이터베이스는 일반적으로 결과적 일관성에 최적화 되어 있음.

#### Monitoring Staleness

- 데이터베이스가 최신 값을 반환하는지 모니터링 하는 것은 중요.
- 리더 기반 레플리케이션에서는 레플리케이션 지연 메트릭을 제공하는 것이 쉬움. 쓰기가 팔로워들에게 같은 순서로 적용되기 때문.
- 하지만, 리더 없는 레플리케이션에서는 쓰기가 적용되는 순서가 유동적. 만약, read repair만 사용한다면 지연을 추적하는 것은 더더욱 어려움.
- 리더 없는 레플리케이션에서의 이런 문제를 해결하기 위한 연구들이 진행중. 그러나 실제로 잘 쓰이지는 않는 상태.

### Sloppy Quorums and Hinted Handoff

1. `w` 또는 `r` 쿼럼을 만족시키지 못한다면, 에러를 반환하는 게 좋을까?
2. 아니면, `n`개 이외의 별도의 노드를 두고, 이 별도의 노드까지 포함하여 `w`를 만족시킨다면, 이를 허용해 주는 게 좋을까?

후자를 가리켜 *sloppy quorum*이라고 함. 굳이 번역하면, 날림 정족수? 그리고 이렇게 임시로 한 노드가 받은 쓰기를 다시 "집(`n`개로 지정됐었던)" 노드로 보내는 것을 가리켜, *hinted handoff*라고 부름.

sloppy quorums는 쓰기 가용성을 높일 때 유용함. 다만, `w + r > n`이 만족하더라도 최신 값을 읽어들이지 못할 수도 있음. 바깥 노드에 최신 데이터가 있을 수도 있기 때문. 따라서, sloppy quorums의 quroum은 전통적인 의미라기 보다, 내구성을 보장해주는 정도의 것.

모든 Dynamo 구현에서는 이것이 선택적임. Riak에서는 기본으로 활성화 되어 있고, Cassandra와 Voldemort에서는 기본으로 비활성화.

#### Multi-Datacenter Operation

리더 없는 레플리케이션은 복수 데이터 센터 운영에 적합함. 동시 쓰기의 충돌, 네트워크 단절, 응답 지연 스파이크 등에 내성을 갖도록 설계되었기 때문.

### Detecting Concurrent Writes

TBD













