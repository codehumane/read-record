# Designing Data-Intensive Application

## Storage and Retrieval

### Data Structures That Power Your Database

```bash
#!/bin/bash

db_set () {
    echo "$1,$2" >> database
}

db_get () {
    grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

- 아주 간단한 데이터베이스.
- 매 라인마다 쉼표로 구성된 키-값 쌍의 텍스트 파일을 활용.
- 기존 값을 갱신하지 않고 계속 쌓기만 하는 append-only.
- 데이터 베이스의 로그가 바로 이런 형태.
- 로그가 너무 커지지 않게 디스크 공간 회수나 오류 처리, 동시성 제어 등의 문제 해결이 필요하긴 하지만, 기본적으로는 같은 원리.
- 하지만, 레코드가 많아지면 검색 성능이 나빠짐. 특정 키를 찾기 위해, 처음부터 끝까지 스캔해야 하기 때문. O(n).
- 키 찾기의 효율성을 위해 활용되는 것이 바로 인덱스.
- 하지만 쓰기 속도는 느려짐.
- 이런 트레이드 오프로 인해 데이터베이스는 모든 것을 인덱싱하지 않음. 사용자의 선택.

#### Hash Indexes

키-값 저장소를 해시 맵으로 인덱싱하기.

- [해시 맵 인덱스 그림](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0301.png) 참고.
- 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지.
- 단순하지만 Bitcask 등 실제로 많이 사용됨.
- 고유키가 많지 않으면서도(메모리에 적재해야 하므로) 값의 갱신이 빈번한 경우에 유리.

만약, 디스크 상의 로그 구조화 파일에 계속 append만 되서 공간이 부족해 진다면?

- 로그를 특정 크기의 세그먼트<sup>segment</sup>로 나누기.
- 세그먼트가 특정 크기에 도달하면, 세그먼트를 닫고 이후의 쓰기는 새로운 세그먼트에 수행.
- 닫힌 세그먼트에 대해서는 일반적인 컴팩션<sup>compaction</sup> 수행.
- 당연히, 여러 개의 세그먼트에 대해서도 컴팩션 가능.

구현 시 주의 사항들

- CSV 형식은 로그에 부적합. 문자열 길이를 바이트 단위로 인코딩 후, 원시 문자열을 인코딩 하는 것이 빠르고 간편함. 이스케이핑도 필요 없어짐.
- 키 관련 값을 삭제하려면 특수한 삭제 레코드(tombstone이라고도 불림)을 추가. 세그먼트 병합 시 이 키의 이전 값들은 무시됨.

추가 전용 로그의 장단점

- 순차적 쓰기 작업으로, 무작위 쓰기에 비해 훨씬 빠름.
- 동시성과 고장 복구에 유리. 고장의 경우 별도의 파일에 추가한 뒤 병합하면 됨.
- 반면, 해시맵은 메모리에 저장해야 빠르므로, 너무 큰 인덱싱은 불가.
- 범위 질의가 비효율적. 해시 맵에서 일일이 모든 개별 키를 조회해야 함.

#### SSTables and LSM-Trees

먼저, 로그 구조화 저장소에 대한 간단한 요약.

- 로그 구조화 저장소 세그먼트는 [이 그림](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0303.png)에서 보듯이 키-값 쌍의 연속.
- 이 쌍은 쓰여진 순서대로 나타남. 또한, 키 값이 같으면 나중의 값이 이전 값에 우선함.

SS 테이블의 등장.

- 만약, 세그먼트에서 일련의 키-값 쌍을 키로 정렬해야 한다면?
- [이 그림](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0304.png)에서 보는 것 처럼 세그먼트 병합시 정렬 상태를 만들 수 있다.
- 이렇게 키로 정렬된 형식을 가리켜 정렬된 문자열 테이블<sup>Sorted String Table</sup>이라고 함. 또는 SS 테이블.

SS 테이블은 해시 인덱스를 가진 로그 세그먼트에 비해 몇 가지 장점을 가짐.

- 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적. 병합정렬 알고리즘과 유사하기 때문. (다만, 이게 왜 해시 인덱스를 가진 세그먼트의 병합 과정에 비해 장점인지는 잘 모르겠음)
- 더 이상 파일에서 특정 키를 찾기 위해 메모리에 모든 키의 인덱스를 유지할 필요가 없음. (DB 인덱스를 생각하면 금방 이해 됨)
- 레코드들을 블록으로 그룹화하고, 디스크에 쓰기 전에 압축할 수 있음. 인메모리 인덱스는 압축된 블록의 시작을 가리키면 됨. 이렇게 하면, 디스크 공간 절약과 I/O 대역폭 사용도 줄임.

##### Constructing and Maintaining SSTables

SSTables를 어떻게 유지할 수 있을까?

- 쓰기가 유입되면, in-memory balanced tree 데이터 구조(red-black tree와 같은)에 추가. 이런 인메모리 트리를 가리켜 종종 `memtable`이라고도 부름.
- memtable의 크기가 임계치를 넘어가면, SSTable 파일로 옮긴다. 트리가 이미 키로 정렬된 키-밸류 쌍이므로 효율적으로 수행 가능. 새로운 SSTable이 디스크에 작성되는 동안, 쓰기는 새로운 memtable 인스턴스에서 계속 됨.
- 읽기 요청을 처리하기 위해, 우선 memtable에서 키를 찾고, 다음으로 가장 최신의 디스크 세그먼트, 그리고 그 다음 세그먼트, ...를 찾는다.
- 종종 백그라운드에서 병합과 압축 과정을 수행. 세그먼트 파일을 합치면서 덮어씌워졌거나 삭제된 값을 버림.

하지만, 만약 데이터베이스가 고장나면?

- 최근의 쓰기들은 유실될 수 있음.
- 이를 피하기 위해 별도의 분리된 로그를 유지.
- 이 로그에는 쓰기가 발생하는 순서 그대로 즉각 기록.
- 고장시 복구를 위한 목적이므로 순서는 상관 없음.
- memtable이 SSTable로 옮겨질 때 마다, 대응되는 로그들은 버려짐.

##### Making an LSM-Tree Out Of SSTables

- 여기서 소개된 알고리즘은 LevelDB와 RocksDB 등에서 사용됨.
- Cassandra와 HBase에는 이와 유사한 저장소 엔진이 사용됨.
- 이런 인덱싱 구조는 원래 *Log-Structured Merge-Tree (LSM-Tree)*라는 이름으로 소개되었음.
- 정렬된 파일을 병합하고 압축하는 원칙에 기반하는 저장소 엔진들은 종종 LSM 저장소 엔진이라 불림.
- 루신(Elasticsearch와 Solr에서 사용되는 인덱싱 엔진)은 *term dictionary*를 저장하기 위해 비슷한 방식을 사용. 키는 단어(*a term*), 값은 이 단어가 포함된 모든 문서의 ID 목록(*the postings list*). 이 매핑이 SSTable 같은 정렬된 파일에 유지됨. 그리고 필요에 따라 백그라운드에서 병합됨.

#### B-Trees

- SS(Sorted String)테이블과 같이 정렬된 키-값 쌍을 유지.
- 따라서, 키-값 검색과 범위 질의에 효율적.
- 가변적 단위인 세그먼트 아니라, (일반적으로) 4KB라는 고정 크기의 블록이나 페이지 단위로 나눔.
- 한 페이지에서 참조하는 하위 페이지의 수를 가리켜 분기 계수<sup>branching factor</sup>라고 함. 보통 수백 개에 달함.
- 키 값의 갱신은 [여기 그림](https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_0307.png) 참고.

##### Making B-Trees Reliable

- 로그 구조화 인덱스와 대조적으로 새로운 데이터를 기존 페이지에 덮어 씀.
- 일부 동작은 여러 다양한 페이지의 덮어쓰기가 수반됨. 고아 페이지에 유의.
- 고장 복구를 위해 디스크 상의 쓰기 전 로그<sup>write-ahead log</sup>를 쌓음. 재실행 로그<sup>redo log</sup>라고도 불림.
- 다중 스레드가 동일한 페이지 갱신에 유의. 보통 레치<sup>latch</sup> 즉, 가벼운 잠금으로 이를 보호함.

##### B-Tree Optimizations

- 페이지를 오버라이트하거나 WAL을 유지하는 대신, 일부 데이터베이스들은 copy-on-write 스키마를 사용. 동시성 제어에 유리. 일종의 READ-COMMITTED.
- 키 전체 대신 축약 버전을 저장. B+ 트리를 일컫는 것.
- 리프 페이지들은 디스크 상에서 연속된 순서로 나타나게끔 배치를 시도.
- 트리에 포인터 추가. 리프 페이지가 양쪽 형제들에 대한 참조를 가지면, 상위 페이지로 가지 않아도 순서대로 키 스캔이 가능.

#### Comparing B-Trees and LSM-Trees

경험적으로 LSM-트리가 쓰기에 빠르고, B-트리가 읽기에 빠름.

##### Advantages of LSM-Trees

- B-트리는 매번 적어도 두 벌의 쓰기를 해야 함. 하나는 write-ahead log, 다른 하나는 트리 페이지 그 자체. 때로는 페이지의 몇 바이트만을 바꾸기 위해 전체 페이지를 한 번에 기록해야 하기도.
- 로그 구조화 인덱스도 SSTable을 병합하고 압축하는 것을 반복하기 때문에 여러 번 데이터를 기록. 한 번의 쓰기가 데이터베이스의 생명주기 동안 여러 번의 쓰기를 야기할 수 있다는 점에서 쓰기 증폭<sup>write amplification</sup>. 
- 쓰기가 많은 애플리케이션에서는 디스크에 기록하는 속도가 성능의 병목이 됨. 따라서, 쓰기 증폭은 성능에 직접적인 비용이 됨. 저장소 엔진이 디스크에 많이 쓸수록, 디스크 대역폭은 줄어들기 때문.
- 제목은 LSM-트리의 장점인데 왜 이런 얘기가 계속 나오는지 의아함.
- 하지만, LSM-트리는 B-트리에 비해 일반적으로 더 좋은 성능을 보임. 종종 낮은 쓰기 증폭을 가지고, 트리에서 처럼 여러 페이지에 대해 덮어쓰기를 하기 보다는 차례대로 SSTable 파일들을 압축하기 때문. 순차적 쓰기가 랜돔 쓰기에 비해 훨씬 더 좋은 성능을 보이는 마그네틱 하드 드라이브에서 특히 중요한 차이.
- LSM-트리가 더 잘 압축되므로 더 작은 디스크 용량을 차지. 반면, B-트리는 파편화로 인해 사용되지 않는 디스크 공간이 남게 됨.

##### Downsides of LSM-Trees

- 압축 과정이 때때로 진행중인 읽기와 쓰기 성능에 간섭을 줄 수 있음.
- 압축 과정은 또한 initial write(memtable → 디스크 로깅과 플러시)가 일어날 때 성능 문제가 될 수 있음.
- 쓰기가 늘어나는 속도를 압축이 따라가지 못하면 디스크 공간이 부족해 질 수 있음.
- 로그 구조화 저장소 엔진은 중복된 키가 여러 세그멘트에 걸쳐 존재할 수 있어 트랜잭션 처리에 불리. 트랜잭션 격리는 키 범위에 대한 잠금을 이용해 구현됨.

#### Other Indexing Structures

기본키 인덱스와 보조 인덱스.

- 지금까지 키-값 인덱스를 살펴봄.
- 키-값 인덱스의 대표적인 예는 기본키 인덱싱.
- 보조 인덱스<sup>secondary index</sup>도 많이 사용됨.
  - 이는 효율적인 조인 수행에 결정적 역할.
  - RDB에서는 `CREATE INDEX` 명령을 사용.
  - 기본키와의 차이는 키가 고유하지 않을 수도 있다는 것.

##### Storing Values Within The Index

인덱스 값의 2가지 종류.

- 인덱스에서의 값은 2가지 중 하나.
- 실제 row(문서, 정점)이거나, 저장된 row를 가리키는 참조.
- 후자의 경우 row가 저장된 곳을 힙 파일<sup>heap file</sup>이라 부르고 순서 없이 데이터를 저장.
- 여러 보조 인덱스가 존재할 경우, 데이터 중복을 피할 수 있다는 점 때문에 후자의 접근 방식이 더 일반적.

힙 파일에서의 값 변경.

- 키의 변경 없이 값만 변경하는 경우라면, 힙 파일 접근법이 효율적.
- 새로운 값이 이전 값 보다 크지만 않다면 그 자리에서 대체될 수 있기 때문.
- 하지만, 새로운 값이 더 크다면, 새로운 공간에 저장되어야 하고, 모든 인덱스를 변경하거나, 포워딩 포인터를 오래된 힙 위치에 남겨두어야 함.

인덱스 된 로우를 인덱스 안에 저장하기.

- 익덱스 자체에 값을 넣어두는 것은 읽기의 성능을 높임.
- 클러스터드 인덱스<sup>clustered index</sup>라고 알려져 있음.
- MySQL의 InnoDB 저장소 엔진에서는 기본키가 항상 클러스터드 인덱스. 그리고 보조 인덱스가 기본키를 참조함.
- SQL Server에서는 테이블 별로 클러스터드 인덱스를 지정할 수 있음.

커버링 인덱스.

- 클러스터드 인덱스와 비 클러스터드 인덱스의 절충안으로, 테이블의 일부 컬럼을 인덱스에 저장할 수 있음.
- 이를 가리켜 커버링 인덱스<sup>covering index</sup> 또는 클러스터드 컬럼이 있는 인덱스<sup>index with included columns</sup>라고 부름.
- 오직 인덱스 만을 이용해서 쿼리에 응답할 수 있게 되는 것.
- 이런 경우를 cover 한다고 말한다. (캐시의 hit가 생각남)
- 읽기의 성능은 높이지만, 추가적인 저장 공간이 필요하고 쓰기의 부하를 더함.
- 또한 DB 입장에서는 트랜잭션을 보장하기 위한 추가적인 노력도 필요해짐.

##### Multi-Column Indexes

결합 인덱스concatenated index</sup>.

- 가장 흔한 다중 컬럼 인덱스 
- 단순히 몇 개의 필드를 연결해서 하나의 키로 만드는 것.
- 전화번호부에서 번호에 대한 (lastname, firstname) 인덱스를 제공하는 것이 한 예.
- lastname으로 번호를 찾거나, lastname-firstname 조합으로 번호를 찾을 때 유리하지만, firstname은 인덱스로 사용 불가.

다중 인덱스<sup>multi-dimensional indexes</sup>.

- 지리 데이터와 같이, 여러 컬럼에 대해 한 번에 질의를 보내는 방법.
- 예를 들면 아래와 같음.

```sql
SELECT *
FROM restaurants
WHERE latitude > 51.4946 AND latitude < 51.5079
	AND longitude > -0.1162 AND longitude < -0.1004;
```

- 표준 B-트리나 LSM-트리는 이런 질의에 효율적으로 응답하기 어려움.
- 한가지 대안은 이차원 위치를 공간-채움 곡선<sup>space-filling curve</sup>(?)를 이용해 1개의 숫자로 변환하여 사용하는 것.
- 좀 더 일반적인 방법은 R-트리처럼 specialized spatial index를 이용하는 것.
- 다중 인덱스는 지리적 위치 이외에도, 커머스에서의 제품 색상 검색(red, green, blue)이나, 날짜 관측을 위한 검색(date, temperature) 등에도 사용.
- 1차원 색인은 한 가지 값으로 필터링 후, 2번째 값으로 추가적인 필터링을 하는 반면, 다차원 인덱스는 주어진 값으로 동시에 범위를 줄일 수 잇음.

##### Full-Text Search and Fuzzy Indexes

오타처럼 유사한 키에 대한 검색을 허용해 주는 퍼지<sup>fuzzy</sup> 질의에 대한 이야기.

- 동의어로 질의를 확장해 주거나,
- 단어의 문법적 변형은 무시하거나,
- 동일 문서 내에 서로 인접해 나타난 단어를 검색해주거나,
- 언어학적인 분석을 통한 여러 다양한 기능들을 지원함.
- 루씬은 편집 거리<sup>edit distance</sup> 범위 내의 허용된 단어를 검색하기도 함.

##### Keeping Everything in Memory

인메모리 데이터베이스의 현실화.

- 디스크는 메인 메모리와 비교해 다루기 어렵다고 함. 그럼에도 불구하고 지속성<sup>durability</sup>과 RAM 대비 비용이 저렴하기 때문에 계속 사용됨.
- 하지만 최근에는 RAM 비용이 점점 낮아지면서 인메모리 데이터베이스가 점점 현실성을 갖게 됨.

내구성<sup>durability</sup>.

- Memcached와 같은 일부 키-값 저장소는 캐싱 용도로만 사용됨. 머신의 재시작으로 데이터가 유실될 수 있음을 인정.
- 하지만 지속성을 추구하는 인메모리 데이터베이스도 존재. 특수 하드웨어를 사용하거나, 디스크에 변경 로그를 남기거나, 디스크에 주기적으로 스냅샷을 남기거나, 인메모리의 상태를 다른 머신으로 복제하거나 하는 방법들을 사용함.
- 인메모리 데이터베이스가 재시작되면, 디스크나 네트워크를 통해 레플리카로부터 상태를 재적재. 단지 지속성을 위해 디스크에 append-only 로그를 남길 뿐. 읽기는 완전히 메모리를 통해 이루어짐.
- 디스크를 함께 사용하는 것은 추가적인 이점을 안겨줌. 외부 도구들을 사용해, 백업하고 검사하고 분석하기 쉬움.
- 참고로, Redis와 Couchbase는 디스크에 비동기로 쓰기 때문에 상대적으로 약한 지속성을 제공.

왜 빠른가.

- 직관과 다르게, 디스크로부터 읽지 않아서 빠른 것은 아님.
- OS가 최근 사용된 디스크 블럭들을 메모리에 적재하기 때문에, 충분한 메모리가 있다면 디스크 기반의 저장소 엔진들도 메모리로부터 데이터를 읽어 들이는 것.
- 인메모리 데이터페이스가 빠른 이유는 디스크에 쓰기 위한 인코딩 오버헤드로부터 자유롭기 때문.

다양한 데이터 모델.

- 디스크 기반의 인덱스로는 구현하기 어려운 데이터 모델들을 제공.
- 예컨대, Redis는 우선순위 큐나 셋 같은 다양한 데이터 구조체를 데이터베이스 같은 인터페이스를 통해 제공. 모든 데이터가 메모리에 있기 때문에, 상대적으로 구현하기 쉽다.

