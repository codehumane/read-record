# 마이크로서비스 아키텍처 구축

> 몇 년 만에 다시 읽는 책. 빠르게 다시 읽어 보는 중인데 여전히 재밌음. 그래서 간단히 기록까지 진행.

## 서비스 모델링하기

### 무엇이 좋은 서비스를 만드는가

- 느슨한 결합. 특정 서비스만 변경하고 배포하기.
- 강한 결합을 일으키는 전형적 실수는 서로 강하게 엮이는 통합 방식의 적용.
- 예컨대 DB를 통한 통합이나 지나친 오케스트레이션.
- 책에서는 오케이스트레이션의 문제를 아래의 문장으로 설명하기도 함.
- 한편, 강한 응집력도 언급. 책의 설명은 부족. 이는 의존성을 줄이기도 하지만, 빠르고 가볍고 이해하기 쉬운 서비스 도출에 도움 될 것.

> 빈약한 CRUD 기반의 서비스에 할 일을 지시하는 소수의 똑똑한 '신'과 같은 서비스

### 경계가 있는 컨텍스트

- bounded context 이야기.
- 각자만의 문맥이 존재하고, 공유될 부분은 인터페이스(번역) 제공.
- 뮤직코퍼레이션 예시.
    - 창고 문맥 내부에는 주문 수집자(주문 내역을 집어다는), 선반(재고 품목의 위치를 보여주는) 등의 개념이 존재.
    - 여기서 외부로 공유되는 것은 재고 품목.
    - 이를 공유 받는 재무 문맥은 계정원장 등의 내부적인 개념을 관리.
- 같은 용어가 서로 다른 문맥에서 조금씩 다른 의미로 사용되는 번역 사례도 소개. (문맥을 구분 짓는 중요한 요소)
- 이런 경계는 모듈이나 서비스의 형태로 구분.
- 성급한 분해도 경계. 기존 코드베이스를 분해 > 처음부터 마이크로서비스.

### 비즈니스 능력

- 빈약한 CRUD 기반의 서비스에 대한 경계. (자율성 부족, 결합도 상승)
- 서비스를 모델링할 때 주요 행위가 무엇인지를 생각할 것.

### 기술적 경계

- 기술에 따라 경계를 나누는 것.
- 프론트엔드, DB 접근 서비스, DB.
- 일종의 수평적 확장.
- 항상 나쁜 것은 아님.
- 하지만 첫 번째가 아닌 두 번째 목표가 되어야 함.

## 통합

### 비동기 아키텍처의 복잡성

- 어느날 작업자 서버들이 줄줄이 죽어 나감.
- 특정 가격 책정 요청이 작업자를 망가뜨렸고,
- 요청은 타임 아웃되어 큐의 뒤로 밀려남.
- 다른 작업자들이 이 요청을 꺼낼 때마다 같은 일이 반복.
- 마틴 파울러가 말한 [catastrophic failover](https://www.martinfowler.com/bliki/CatastrophicFailover.html).
- 버그도 잘못이지만 재시도 최댓값도 설정하지 않았던 것.
- 필요하면 잘못된 메시지도 확인할 수 있어야 하고 재현도 가능해야 했음. (결국 UI로 만들었다고)
- 실패한 메시지가 이송되는 message hospital 또는 DLQ를 구현해야 했다고 함.
- 요청을 추적할 수 있도록 correlation ID의 사용도 적극 검토할 것.

### 버전 관리

- XPath를 이용한 Tolerant Reader 패턴 사용 등 가능한 버전 분기를 지연.
- CDC를 통해 호환성을 깨뜨리는 변경 일찍 찾아내기.
- 클라이언트가 서비스 버전 번호만 보고도 통합을 판단할 수 있도록 semantic versioning 사용.
- 다른 버전의 엔드포인트와 공존. 다만, 확장-수축 패턴을 통해 모든 코드를 관리하고 테스트하는 부담을 줄여라.
- 드물지만, 버전이 다른 독립된 서비스를 동시에 운영하기도. 추천 X. 버그 발견 시 두 벌을 수정해야 하고, 라우팅에 부가적 로직이 필요하며, 저장된 데이터가 모든 버전에 호환되어야 하는 노력이 수반됨.

### API 구성

- 여러 컴포넌트로 구성된 화면이 있음.
- UI 측에서 컴포넌트 별로 다른 서비스를 호출할 수도 있으나 호출 수와 데이터 양 등에서 문제가 됨.
- 한편, 화면에 필요한 UI를 API로부터 제공 받을 수도. 하지만 다양한 종류(HTML, 네이티브, ...)의 지원은 쉽지 않음.
- API 게이트웨이를 둘 수도 있음. 하지만, 동작이 많아지면 이 계층이 두터워지고 재앙(독립적 릴리즈가 어려워지는 등)이 되기도 함.
- 대안으로 BFF 제시. 특정 UI에 집중하는 팀마다 전용 서버 측 컴포넌트도 담당.

## 테스팅

### 테스팅의 종류

- 아래 그림은 브라이언 마릭의 테스팅 사분면.
- 시스템을 테스트하는 것에는 여러 측면이 있음을 드러내기 위한 설명들.
- 물론, 가능한 한 많은 자동화를 추진.
- 책에서는 자동화 테스트 영역만을 다룸.

![testing-quadrants](https://lisacrispin.com/wp-content/uploads/2011/11/Agile-Testing-Quadrants.png)

### 테스트의 범위

- 아래 그림은 마이크 콘의 테스트 피라미드.
- 이는 목표로 하는 테스트의 범위와 그 비율에 대해 생각하게 해 줌.

![](https://www.ontestautomation.com/wp-content/uploads/2014/06/pyramid.png)

#### 단위 테스트

![unit-test-scope](https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/bdms_0704-4b80ddb5e33a9fca7feef12e3fe605e1.png)

- 일반적으로 단일 함수나 메서드 호출을 테스트.
- 서비스 실행 X. 외부 파일이나 네트워크 연결도 제한.
- 매우 빠름. 비즈니스 중심이라기 보다 기술 중심.
- 이 테스트의 목표는 기능이 정상 동작하는지에 대한 빠른 피드백.
- 코드의 재구성이나 리팩토링을 도와주며, 작은 범위의 테스트들이 우리의 실수를 바로 잡아줌.

#### 서비스 테스트

- 사용자 인터페이스를 우회해서 서비스들을 직접 테스트.
- UI에 서비스를 제공하는 클래스의 집합만을 테스트 하기도.
- 외부 협업자를 스텁으로 만들어 범위를 서비스 자체로 제한함.
- 테스트 격리를 통해 문제를 더 신속히 발견하고 해결하기 위함.
- 실제 DB와 연결하거나, 스텁화된 협업자(진짜가 아닌 스텁)들과 네트워크를 통해 테스트하기도.

![service-test-scope](https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/bdms_0705-53248bf070e7375f7a0d2dca8a2d597a.png)

#### 엔드 투 엔드 테스트

- 시스템 전체에 대해 수행하는 테스트.
- 실환경과 유사하므로 더 강한 확신과 안심.
- 한편, 테스트 범위가 넓어짐.
- 이로 인해, 시간이 오래 걸리고 그만큼 피드백 주기도 늦어짐.
- 더불어, 어디가 문제인지를 찾아내기가 쉽지 않음.

![end-to-end-test-scope](https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/bdms_0706-ae2c95cfc38d5a7660b69fac6f41988b.png)

#### 얼마나 많은 테스트가 필요할까?

- 단위 테스트 4,000개. 서비스 테스트 1,000개. 엔드투엔드 테스트 60개. -> 필자의 사례
- 이 때의 문제는 느린 테스트와 긴 피드백 주기.
- 테스트 아이스크림콘이나 역피라미드라고 불리는 안티패턴.
- 따라서, 테스트 범위를 작은 범위의 테스트로 교체했다고 함.

### 서비스 테스트 구현하기

- 번역이 이상한 듯 하여 원서를 함께 봄. 원서가 잘 읽힘.
- 서비스 테스트에서의 그림처럼, 다운스트림 협업자에 대한 스텁 서비스가 필요.
- 스텁 대신 목을 사용하기도. 예상된 부수 효과가 일어나는지를 검증 가능. (Mockito#verify를 말하는 듯)
- 하지만, 미리 정의된 호출만 가능. 반면에, 스텁은 0, 1, 여러 번 호출해도 문제 없음.
- 따라서, 목은 깨지기 쉬운 구조. 필자는 그래서 스텁을 선호. (개인적으로는 반대)
- 목과 스텁의 차이는 마틴 파울러의 [여기 글](https://martinfowler.com/articles/mocksArentStubs.html#TheDifferenceBetweenMocksAndStubs) 참고.
- 스텁/목 서버를 이용하기도 함.

### 까다로운 엔드 투 엔드 테스트

- 새 버전의 고객 서비스를 내 놓아야 한다고 가정.
- 새 버전을 바로 배포 해도 되지만, 이로 인해 업스트림의 헬프데스크와 웹 숍 서비스가 깨질 수 있음.
- 그래서 서비스들을 모두 다같이 배포. 그리고 버그가 있는지를 테스트.
- 다소 서툰 방법이긴 하지만, 이 테스트를 아래 그림처럼 파이프라인에 추가.

![](https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/bdms_0707-24947a8d5e75de259b43c9a11281e022.png)

- 하지만, 다른 서비스들의 어떤 버전을 배포해야 하는지를 결정하기 어려움.
- 또한 각 서비스 파이프라인에서 수행되는 엔드투엔드 테스트들이 중복됨.
- 그래서 아래와 같이 fan-in 모델의 파이프라인을 구성.

![](https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/bdms_0708-7ca941c35dd74394726b32d797630821.png)

### 신뢰할 수 없고 취약한 테스트

- 테스트 범위가 넓은 테스트에는 단점들이 많음.
- 테스트와 관계 없이 특정 서비스가 다운되거나 임시적 네트워크 실패에 의해 전체가 실패하게 되기도.
- 같은 코드더라도 어떤 실행에서는 성공하고 어떤 실행에서는 실패하기도(비결정적). 스레드의 경쟁 상태나 타임아웃 등이 원인.
- 이런 문제들로 인해 테스트가 신뢰를 잃어감. normalization of deviance.
- 그 외에도 불분명한 소유권, 긴 소요 시간, 빌드가 되는 동안의 긴 적체, 매번 전체 서비스를 함께 배포 등의 문제를 다룸.

## 모니터링

### N services, M servers

아래 3가지로 구분지어 상황을 이야기.

1. 단일 서비스, 단일 서버
2. 단일 서비스, 다수 서버 (w/로드밸런서)
3. 다수 서비스, 다수 서버 (w/로드밸런서)

어느 상황이든 시스템 상태, 헬스체크, 로깅, 응답 시간 등의 모니터링이 필요. 2번과 3번에서도 1번에서와 같이 종합적 시각을 가질 수 있어야 함. 동시에 어느 서비스의 어느 서버의 문제인지 세부적인 구분도 가능해야 함. 서비스의 문제인지 서버의 문제인지 등의 구분도 물론 필요. 2번까지는 ssh-multiplexers 등으로 충분할지 모름. 그러나 3번으로 갈 수록 각종 지표와 로그의 중앙 수집이 필요.

1번과 2번, 3번을 그림으로 비교하니, 그 복잡성과 비용이 다시 한 번 와 닿음. 너무 당연하게 하고 있었던 게 아닌가 싶다.

### Metric Tracking Across Multiple Services

- 여러 서버들의 지표를 한 곳에서 보는 것이 필요.
- 하지만, 복잡한 시스템일 수록 어떤 게 '좋은' 상황인지 판단이 어려움.
- 초당 50개 이상의 4XX HTTP 에러가 나면 문제일까?
- 애플리케이션 시작 후 CPU가 20%까지 늘어나면 문제인가?
- 이를 판단하기 위해, 충분히 오랜 기간 동안 시스템 상태를 관찰하고 이해해야.
- 이를 통해 capacity planning도 가능.
- 이를 돕는 도구로 Graphite를 소개.

### Service Metrics

TBD
