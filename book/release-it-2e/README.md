# Living in Production

1. feature complete != production ready
2. crash, hang, lose data, violate privacy, lose money, crazy real uses, globe-spanning taffic, virus writing mobs, …
3. 최선의 계획을 세우더라도 나쁜 일이 일어난다는 것을 받아들여야 함. 따라서, 할 수 있는 것들을 최대한 하되, 어떤 심각한 상황에서도 전체 시스템이 회복될 수 있어야 함.

## Aiming for the Right Target

1. "고객의 첫 번째와 마지막 이름은 필수고, 중간은 선택이에요"와 같은 테스트를 통과하기 위함이 아님.
2. 대신, "design for production"

## The scope of the Challenge

1. 사용자는 늘어나고, 더 높은 수준의 가용성이 요구됨.
2. 빌드 비용이 저렴하고, 사용자에게 유용하고, 운영 비용이 적은 소프트웨어를 빠르게 만들어내야 함.
3. 조그마한 워드프레스에 적절한 설계는 대규모 확장과, 트랜잭션, 분산 시스템 등의 요구에 실패할 것.

## A Million Dollars Here, a Million Dollars There

1. 설계와 아키텍처 결정은 또한 재정적 결정.
2. 이런 결정들은 구현 비용과 더불어 후속 비용(가용성이나 배포 비용 등의 운영을 가리키는 듯)도 함께 고려해야 함.
3. 기술적 그리고 재정적 관점은 이 책에서 반복적으로 다루는 중요한 테마.

## Use the Force

1. "Use the Force"가 무슨 말인가 했더니, 스타워즈에 나오는, 앞을 내다보라는 식의 말인 것 같다.
2. 저자는 열성적인 애자일 지지자이긴 하지만, 초기 결정의 중요성에 대해 말하고 있음.
3. 이 결정이 시스템의 궁극적 모습에 지대한 영향을 미치기도 하고, 때로는 돌이킬 수 없기도 함.
4. 앞으로 책에서, 어떤 문제에 대한 대안을 소개하고, 이들이 선택된 이후에 어떤 영향을 미치는지 살펴본다고 함. 궁금.

## Pragmatic Architecture

1. 저자는 아키텍트를 2개로 분류하는데, 하나는 상아탑<sup>ivory towel</sup>이고, 다른 하나는 실용주의.
2. 높은 추상화를 추구하기 보다는 현실적 문제를 다룸. 메모리 사용량, CPU 요건, 대역폭, 하이퍼스레딩과 CPU 바인딩의 이점과 단점 등을 논의.
3. 특별한 이야기는 아님. 개인적으로는 지면이 아까운..

# Case Study: The Exception That Grounded an Airline

1. 정기적인 DB 유지보수가 있었고,
2. 이 때, A라는 DB로부터 B라는 DB로 페일오버가 예정됨.
3. 서비스에 이상이 없는지를 확인할 수 있는 모니터링과 함께,
4. 무중단 DB 페일오버를 수동으로 진행.
5. 문제 없이 완료 후 작업은 모두 끝남.
6. 하지만 몇 시간 후 항공사 시스템에 전면 장애가 발생.
7. 장애 발생 시의 즉각적인 대응과 포스트 모텀 등을 이야기 한 뒤(이런 부분들이 잼있었음),
8. 문제의 원인이 된 코드도 보여줌. CF라는 시스템은 아래의 코드만으로 이뤄진 애플리케이션이 실행되고 있었다고 함.

```java
public class FlightSearch implements SessionBean {

    private MonitoredDataSource connectionPool;

    public List lookupByCity(...) throws SQLException, RemoteException {
        Connection conn = null;
        Statement stmt = null;

        try {
            conn = connectionPool.getConnection();
            stmt = conn.createStatement();

            // ...
        } finally {
            if (stmt != null) {
                stmt.close();
            }
            if (conn != null) {
                conn.close();
            }
    }
}
```

9. `stmt.close()`가 SQLException을 던지기 때문.
10. 데이터베이스의 페일오버 시 연결이 끊겼고,
11. 이 때 `stmt.close()`의 호출이 예외를 발생시켰으며,
12. 이로 인해 커넥션이 종료되지 않고 리소스가 누수되어서 발생한 문제.

# Stabilize Your System

엔터프라이즈 소프트웨어는 냉소적이어야 함.
1. 나쁜 것이 일어날 것을 예상하고, 그것이 일어났을 때 놀라지 않는 것.
2. 스스로를 또한 믿지 않기 때문에 장애 시의 대비책도 마련.
3. 다른 시스템과 너무 밀접<sup>intimate</sup>해지는 것을 거부. 다치는 것을 염려하기 때문.
4. 앞선 항공사 사례에서의 예외는 충분히 회의적이지 않았음.

낮은 안정성은 많은 실질적 비용을 초래. 수익은 물론, 평판도 마찬가지.

좋은 안정성에 꼭 많은 비용이 들일 필요는 없음.
1. 아키텍처나 설계, 저수준 구현 시 많은 안정성을 위한 레버리지 포인트들이 존재.
2. 이 레버리지는 기능적 요구사항과 상충되는 길이 아니며,
3. 안정적이지 못한 것과 안정적인 것을 만드는데 들어가는 시간은 동일하다고.

## Defining Stability

대부분의 사람들은 "안정성<sup>stability</sup>"을 아래와 같이 정의한다고 함.

> 강건한 시스템은 일시적 충격<sup>impulse</sup>이나, 지속적인 스트레스<sup>stress</sup>, 컴포넌트의 실패<sup>failure</sup>에 상관 없이, 트랜잭션 처리를 지속함.

여기서의 트랜잭션이란, 시스템에 의해 처리되는 일의 단위를 추상화한 것. DB 트랜잭션 X. "customer places order"와 같이 다른 시스템(카드사 등)과의 통합이 포함될 수도. 그리고 시스템이란, 사용자의 트랜잭션을 처리하기 위한 하드웨어, 애플리케이션, 서비스의 상호 의존적이고 완전한 집합을 가리킴.

## Extending Your Life Span

시스템 수명에 대한 주요 위험 요소는 메모리 누수와 데이터 성장이라고 함.

1. 긴 시간을 두고 일어나는 일이기에, 테스트 기간에 잡기는 어려운 문제들.
2. 테스트에 관해서는 머피의 법칙을 따르자. 테스트 안 한 것이 곧 문제가 되는 것.
3. 42시간이 지나야 생기는 메모리 누수, 자정이 지나야 생기는 충돌 문제 등.

그런데, 이런 장기적(?) 버그는 어떻게 찾을 수 있을까.

1. 개발 장비를 하나 마련해서 JMeter, Marathon 등으로 장기 버그를 테스트.
2. 심한 부하를 주기 보다는, 적정한 양의 요청을 지속적으로 보내고,
3. 이따금 적은 양의 요청을 보내게 하라(커넥션 풀이나 방화벽 시간 제한 등의 문제를 잡기 위함).
4. 돈이 문제가 된다면 적어도 중요한 부분만이라도 테스트.

이런 테스트가 없다면, 프로덕션 환경이 곧 장기 테스트 환경이 될지도.

## Failure Modes

1. 갑작스런 충격이나 과도한 긴장<sup>strain</sup>(스트레스가 가해진 모습을 가리킴)은 재앙적 실패<sup>catastrophic failure</sup>를 불러올 수 있음.
2. 일부 컴포넌트에 장애가 생기고, 이것에 의존하는 다른 컴포넌트에 급속도로 장애가 전파되는 것을 가리킴.
3. 다양한 고장 모드는 반드시 일어남. 충격을 수용하고 나머지 시스템을 보호하는 안전한 고장 모드를 만들어야 함.
4. 이런 종류의 자가 보호가 전체 시스템의 회복 탄력성<sup>resilience</sup>을 결정.
5. Chiles라는 사람은 이를 가리켜 "crackstoppers"라고 부름.

## Stopping Crack Propagation

고장 모드 설계는 항공사 사례에 적용 가능함. SQLException를 부적절하게 핸들링 했던 것이 원인인데, 이를 막을 수 있었던 지점을 저수준부터 고수준까지 소개. 먼저, DB 연결 설정부터.

1. 가용한 풀이 없으면 요청 스레드를 막도록 설정되어 있었기 때문에, 결국 요청을 처리하는 모든 스레드를 가두게 됨.
2. 자원이 고갈되면 더 많은 커넥션을 생성하도록 설정할 수도 있었을 것. (새로 바뀐 DB에 대해 새로운 커넥션이 맺어지도록)
3. 또는 호출자를 영원히 멈추게 하는 대신, 제한된 시간 동안만 막도록 설정할 수도 있었을 것.
4. 참고로, 아래 내용은 HikariCP의 `maximumPoolSize`에 대한 설명. 더불어, 이런 글([Hikari, About Pool Sizing](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing))도 있음. 예전에는 못 봤던 문서.

> "This property controls the maximum size that the pool is allowed to reach, including both idle and in-use connections. Basically this value will determine the maximum number of actual connections to the database backend. A reasonable value for this is best determined by your execution environment. When the pool reaches the size, and no idel connections are available, calls to getConnection() will block for up to `connectionTimeout` milliseconds before timing out."

다음으로, CF가 다른 애플리케이션을 호출할 때 RMI를 사용한 것에 대해.

1. RMI는 기본적으로 타임아웃이 없음. 호출이 블럭되면 영원히 대기.
2. RMI 소켓에 타임아웃을 설정하는 것이 좋았을 것.
3. 혹은, HTTP 요청을 타임아웃과 함께 사용.
4. 블럭된 스레드를 클라이언트가 버리는 것도 방법.

좀 더 큰 수준에서 본다면.

1. CF 서버를 2개 이상의 서비스 그룹으로 나누는 것도 방법.
2. 모든 그룹이 여전히 다 죽을 수도 있지만, 항상 그런 것은 아님.

이보다 더 큰 수준의 아키텍처 이슈로 본다면.

1. CF에서 요청/응답 메시지 큐를 사용할 수도 있음.
2. 혹은 [튜플 스페이스<sup>tuple space</sup>](http://wiki.c2.com/?TupleSpace)에서 검색 조건에 맞는 항공편을 찾을 수도.
3. 아키텍처의 결합도가 높아질수록, 오류가 전파될 가능성은 높아짐.
4. 반대로 말하면, 아키텍처 결합도가 낮을 수록 충격을 흡수함. 에러를 증폭시키는 대신 줄여주기도.

## Chain of Failure

1. 하나의 작은 이슈가 다른 이슈를 낳고, 그리고 이로 인해 또 다른 이슈가 생기고, ...
2. 이런 일련의 사건들이 모두 똑같이 일어날 확률은 매우 낮음. 그러나 각각은 독립사건.
3. 그러나, 사건의 조합은 독립적이지 않음. 특정 지점이나 레이어의 장애는 이에 의존하는 다른 지점의 장애를 일으킬 가능성이 큼.
4. 예컨대, DB가 느려지면 애플리케이션 서버들의 메모리는 고갈될 가능성이 높음.
5. 3가지 용어 정의를 잠깐 하고 가면 아래와 같음.

```
Fault: 소프트웨어의 내부 상태를 비정상적으로 만드는 상황. 지연 버그, 체크되지 않은 경계 조건이나 외부 인터페이스 등에 의한 것.
Error: 비정상적인 행위가 가시적인 것. 트레이딩 시스템이 갑자기 100억 달러를 사들인다거나 하는 것.
Failure: 응답하지 않는 시스템. 
```

6. 실패<sup>fault</sup>는 틈을 열고, 에러가 되며, 에러는 장애가 됨.
7. 당연하게도, 높은 수준의 결합도를 가진 복잡한 시스템은 에러로 이어질 수 있는 실패 전파의 경로가 많음.
8. 가능한 실패에 대해 미리 준비할 수 있는 한 가지 방법은 모든 외부 요청, I/O, 리소스 사용을 살피고, 잘못된 수 있는 경우를 따져보는 것.

```
초기 연결이 맺어지지 않는다면?
연결을 맺는데 10분이 걸린다면?
연결은 맺었는데, 다시 끊어진다면?
연결을 맺었는데, 응답이 오지 않는다면?
질의 응답이 오는데 2분이 걸린다면?
10,000개의 요청이 동시에 들어온다면?
`SQLException` 에러 메시지를 로깅하는데 디스크가 꽉 차있다면?
```

9. 실패는 반드시 발생하며, 모든 것을 예방할 수는 없음.
10. 그리고 이 실패가 에러가 되지 않도록 막음과 동시에 실패나 에러를 감수할 것인지 결정도 해야함.

# Stability Antipatterns

## Integration Points

1. 저자는 1996년 이래로 단일 모드로 된 웹사이트를 본 적이 없다고 함.
2. 모든 프로젝트는 통합된 프로젝트였으며, [나비](https://www.safaribooksonline.com/library/view/release-it-2nd/9781680504552/images/stability/butterfly.png)나 [거미](https://www.safaribooksonline.com/library/view/release-it-2nd/9781680504552/images/stability/spiderweb_orderly.png) 형태 중 하나.
3. 이런 연결들은 모두 통합 지점이며, 각각은 모두 시스템을 붕괴시킬 수 있는 요소.
4. 책에서는 통합 지점을 가리켜 "number-one killer of systems"라고 표현하기도 함.
5. 모든 소켓, 프로세스, 파이프, 원격 프로시저 호출, 데이터베이스 연결 등이 여기에 해당.
6. 뒤이어서, 통합 지점이 문제가 될 수 있는 몇 가지 상황과 각각에 대한 대처 방안에 대해 살펴봄.

### SOCKET-BASED PROTOCOLS

1. 많은 상위 수준의 통합 프로토콜은 소켓 위에서 실행되며, 프로토콜들은 소켓이 문제가 되는 경우를 위한 실패 모드를 지원.
2. 가장 단순한 실패 모드는 원격 시스템이 연결을 거부할 때 발생. 하지만, 연결 거부는 주로 문제가 되지 않음. 많은 언어들이 API를 통해 연결 실패가 발생할 수 있음을 잘 알려주기 때문.
3. 한 가지 주의할 것은 연결할 수 없음을 발견하는 데 오랜 시간이 걸릴 수 있다는 것.
4. 잠시, TCP/IP 네트워킹에 대해 소개하고 넘어감.

> 네트워크 연결을 표현하는 많은 그림들은 박스와 화살표를 사용함. 하지만, 이는 추상화한 것을 다시 또 추상화한 것. 네트워크 "연결"은 논리적 언어. 네트워크 상에서 우리가 볼 수 있는 것은 단지 패킷(물론, 패킷 또한 추상화 된 것. 전기와 광자, ...). 이들 패킷은 TCP/IP의 IP에 해당. TCP는 불연속적인 패킷들의 주고 받음을 어떻게 연속적인 연결로 보이게 할 것인가에 대한 약속.
> 
> TCP는 연결을 열기 위해, "three-way handshake"를 사용. 호출자가 SYN 패킷을 원격 서버의 포트에 전달. 아무도 포트에 대해 리스닝하고 있지 않다면, 즉각 TCP "reset" 응답을 반환. 호출 애플리케이션은 예외 또는 잘못된 응답 값을 받게 됨. 이 과정은 매우 짧은 시간 내에 일어나며, 같은 스위치로 연결된 장비라면 10ms 이하로 소요. 목적지 포트에 대해 리스닝하고 있는 애플리케이션이 있다면, 원격 서버는 SYN/ACK 패킷(연결을 받을 준비가 됐다는 의미로)을 응답. 이 응답을 받은 호출자는 다시 ACK를 전송함. 이 세개의 패킷들이 바로 "연결"을 만들어 냄. 애플리케이션들은 이제 데이터를 서로 주고 받을 수 있음.

5. 포트는 "리스닝 큐"를 가지고 있음. 이는 얼마나 많은 대기 연결(SYN은 보내졌지만, SYN/ACK를 응답하지 않은)을 네트워크 스택에 허용할지를 정의. 리스닝 큐가 꽉 차면, 이후의 연결 시도는 재빨리 거부됨. 리스닝 큐는 최악의 장소.
6. 소켓이 상태를 부분적으로 형성하고 있는 동안, open 상태의 스레드는 OS 커널 안에서 대기하게 됨. 원격 애플리케이션이 연결을 받아들이거나, 커넥션이 타임아웃이 될 때까지.
7. 연결도 되고 요청도 보냈지만, 원격 서버가 요청을 읽어들이거나 응답을 반환하는 데 오랜 시간이 걸릴 수도 있음. read 요청(open 상태의 스레드와 마찬가지로) 또한 대기 상태가 될 수 있음.
8. 네트워크 실패의 종류는 2가지. 빠르거나 느리거나. 빠른 실패는 "Connection refused" 같은 예외를 즉각 일으킴. 느린 실패(중단된 ACK 같은)는 예외를 던지기까지 몇 분 동안 스레드를 대기시킬 수 있음. 대기된 스레드는 다른 트랜잭션을 처리할 수 없고, 전체 가용 자원은 줄어듦. 만약, 모든 스레드가 대기하게 되면, 서버는 결국 중단됨.

> "Clearly, a slow response is a lot worse than no response."

### THE 5 A.M. PROBLEM

1. 매일 아침 5시만 되면 행이 걸렸고, 재시작으로 항상 문제가 해결됨.
2. 이 문제가 생기고 나서 3일이 되는 날 스레드 덤프를 생성.
3. 인스턴스는 살아 있었지만, 요청을 처리하는 모든 스레드가 Oracle JDBC 라이브러리 부근에서 블럭 상태. 특히 OCI 호출부 안에서.
4. synchronized 메서드를 진입하려고 대기하는 스레드를 제외하면, 활성화 된 스레드들은 모두 저수준의 소켓 읽기나 쓰기 호출에 사용되고 있는 것으로 보였음.
5. 다음 단계는 tcpdump 또는 ethereal(현재는 Wireshark라고 불리는).
6. 이 도구를 통해 살펴보니, 애플리케이션 서버에서 일부 패킷들이 데이터베이스 서버로 전송됐지만, 응답이 없는 상태였음.
7. 하지만, 모니터링 도구를 통해 살펴보면 데이터베이스는 살아 있으며 건강하다고 표시됨.
8. 블럭 상태의 락은 없었으며, 큐 갯수는 0개였고, I/O 비율은 정말 낮았음.
9. 그러고 나서 하루가 지나고 문제는 어김 없이 다시 발생.
10. 이번에는 데이터베이스 네트워크 트래픽을 살펴볼 수 있었음.
11. 그런데 트래픽이 전혀 없었음. 이것이 큰 단서.
12. 앞서 소켓 연결의 추상화를 언급했었음. 양쪽의 컴퓨터 메모리에 소켓이 연결 상태라고 표시되어 있으면 그게 곧 연결인 것. 하루 종일 1개의 패킷도 보내지 않는 중이라고 하더라도, 라우트가 변경되더라도, 물리적 링크가 다시 연결되더라도 말이다.
13. 방화벽은 특수화 된 라우터에 지나지 않음.
14. 각 방화벽 내부에는 접근 제어 목록 집합이 정의되어 있음.
15. SYN 패킷이 들어오면 방화벽은 허용하거나(목적지로 전달), 거부하거나(TCP 리셋 패킷을 다시 돌려줌), 무시하거나(응답 없이 패킷을 버림) 중 하나를 취함.
16. 연결이 허용되면 방화벽은 이 엔트리를 내부 테이블에 기록하고, 엔드포인트가 일치한 이후 패킷들에 대해서는 요청을 라우팅해 줌.
17. 이 방화벽 이야기가 아침 5시 문제와 무슨 관계가 있을까?
18. 핵심은 방화벽의 연결 허용 기간이 유한하다는 것. TCP는 무한한 기간의 연결을 허용하더라도 말이다.
19. 마지막 패킷 시간으로부터 많은 시간이 지났다면, 이 연결을 죽었다고 간주하고 이후에 들어오는 패킷을 버림(무시).
20. 라우터로써, 방화벽은 ICMP 리셋을 전달할 수도 있었으나, 악의적인 공격에 의한 ICMP 트래픽을 억제하기 위해 설정되어 있었음.
21. 결국, 반쯤 열린 소켓은 읽기나 쓰기 시도시 TCP 리셋이나 에러를 받을 수 없었음. 단지, ACK를 기다리고 있을 뿐.
22. JDBC 연결을 사용하기 전에 "SELECT SYSDATE FROM DUAL" 같은 SQL로 유효성을 검증할 수도 있으나, 이 또한 스레드를 행 걸리게 하는 일일 뿐.
23. 대신에 오라클의 dead connection detection을 사용. 이 자체의 기능이 필요했다기 보다, 단지 주기적으로 클라이언트에게 PING 요청을 보내게 함으로써, 방화벽에 마지막 패킷 시간을 계속 최신으로 유지하기 위함.
24. 여기서의 교훈은 추상화된 수준에서 해결되지 않는 문제들이 있다는 것. 때로는 두 단계 정도 아래로 내려와 현실을 마주해야 할 필요도 있음.

### HTTP PROTOCOLS

HTTP 기반의 프로토콜은 소켓을 사용함. 따라서, 앞서 언급했던 문제들에 취약. 여기에 HTTP 자체의 이슈들도 더해짐. 예컨대, 아래와 같은 것들이 있음.

1. 수신자가 TCP 커넥션 연결을 받아들였지만, HTTP 요청에 대한 응답을 하지 않음.
2. 연결은 받아들였지만, 요청을 읽어들이지 못할 수도 있음. 요청 바디가 너무 큰 경우, 수신자의 TCP 윈도우를 꽉 차게 하고, 호출자의 TCP 버퍼도 차게 되면서, 소켓의 쓰기가 블럭될 수 있음.
3. 호출자가 반환한 응답 상태를 호출자가 다루는지 모를 수 있음.
4. 수신자가 반환한 컨텐츠 타입을 호출자가 이해하지 못할 수 있음. 예를 들어, JSON 요청을 했는데 404 에러 HTML 페이지가 반환된다거나.
5. 수신자가 JSON을 응답한다고 하면서 실제로는 평문을 반환할 수도 있음.

따라서, 세부적인 제어가 가능한 클라이언트 라이브러리(커넥션과 읽기 타임아웃 등이 제공되는)를 사용하는 것이 좋음. 더불어, 응답을 바로 도메인 객체로 매핑하려는 라이브러리는 사용 X. 기대를 충족하는 응답인지를 먼저 확인할 수 있어야 함.

### VENDOR API LIBRARIES

그냥, 왠만해서는 쓰지 말라는 이야기.

### COUNTERING INTEGRATION POINT PROBLEMS

통합이 없는 시스템은 드물고, 대부분 쓸모도 없음. 통합 지점을 어떻게 안전하게 만들 수 있을까?

1. 가장 효과적인 안정성 패턴은 *circuit breaker*와 *decoupling middleware*(뒤에서 다루는 내용들).
2. *test harness*를 활용한 테스팅 또한 도움이 됨.

냉소적인 소프트웨어는 형태(잘못된 헤더 형태 등)나, 기능 위반(비정상적인 연결 종료 등)을 다룰 수 있어야 함.

### REMEMBER THIS

1. Beware this necessary evil: 모든 통합 지점은 결국엔 어떤 식으로든 실패함.
2. Prepare for the many forms of failure: 통합 지점 실패는 다양한 형태를 띰. 다양한 네트워크 오류부터 문법 에러까지. 그리고 약속된 프로토콜을 통해 에러가 오는 감사한 경우도 없을 것.
3. Know when to open up abstractions: 통합 지점 실패를 디버깅할 때는 종종 저수준을 살펴야 하기도. 패킷 스니퍼나 네트워크 진달 도구가 도움이 됨.
4. Failure propagate quickly: 코드가 충분히 방어적이지 않다면, 원격 시스템의 실패는 보통 실패 전파로 이어짐.
5. Apply patterns to avert integration point problems: Circuit Breaker, Timeouts, Decoupling Middleware, Handshaking 등이 도움이 될 것.

## Chain Reactions

1. 스케일 아웃을 취하고 있다고 하더라도, 부하 관련 충돌이나 자원 누수와 같은 결함은 연쇄 반응으로 이어질 수 있음.
2. 예를 들어, 클러스터에서 특정 노드가 부하로 인해 문제가 생겼다고 해보자.
3. 메모리 누수일 수도 있고, 부하가 심한 상황에서 발생하는 레이스 컨디션일 수도 있음.
4. 그래서 특정 노드가 클러스터에서 빠지면, 나머지 노드들이 추가로 부하를 얻게 됨.
5. 부하 관련 이슈이므로 나머지 노드들 역시 같은 이슈를 겪을 가능성이 높아짐.
6. 결함을 제거하는 것이 연쇄 반응을 막을 수 있는 유일한 방법.
7. Bulkhead 패턴처럼 레이어를 여러 개의 풀로 나누는 것이 때때로 도움이 되기도 함.

## Cascading Failures

1. 한 레이어에서 균열이 생기고, 호출부 레이어에도 영향을 미치면서 실패가 점점 증폭되어 전파됨.
2. 예를 들어, DB가 먼저 고장이 나면, 이 DB를 호출하는 애플리케이션들 또한 문제를 겪게 됨. 어떤 문제를 겪게 되는지는 애플리케이션이 문제를 어떻게 다루는지에 따라 달려 있음. 잘못 다루고 있다면, 실패 전파로 이어지는 것.
3. 섣부른 재시도는 호출부의 스레드를 더 낭비하게 할 수도.
4. 오히려, 이러한 실패 전파를 막을 수 있는 가장 효과적인 방법은 Circuit Breaker와 Timeout.

## Users

### TRAFFIC

수용량<sup>capacity</sup>을 벗어나는 수준의 요청이 들어오면 시스템은 어떻게 반응하는가?

> "Capacity" is the maximum throughput your system can sustain under a given workload while maintaining acceptable performance.

#### Heap Memory

1. 메모리는 수용량을 벗어나기 쉬운 대상 중 하나.
2. 인 메모리 세션을 사용하는 경우, 마지막 요청으로부터 세션 타임아웃이 일어나기 까지의 데드 타임도 존재하고, 사용자의 증가에 따라 메모리 사용량도 그대로 늘어나기 때문에 종종 문제가 됨.
3. 사용자에게 OOM 오류가 전달되는 것도 나쁘지만, 최악은 메모리 부족으로 에러 로그도 남지 않는 것.
4. 이를 방지하는 한 가지 방법은 인 메모리 세션을 최대한 가볍게 유지하는 것.
5. 혹은, 메모리가 충분할 때는 많은 데이터를 가지고 있다가, 메모리가 부족해지면 알아서 제거되도록 하는 것도 방법. ([java.lang.ref.SoftReference](https://docs.oracle.com/javase/7/docs/api/java/lang/ref/SoftReference.html)를 소개하고 있음)

```java
MagicBean hugeExpensiveResult = ...;
SoftReference ref = new SoftReference(hugeExpensiveResult);

session.setAttribute(EXPENSIVE_BEAN_HOLDER, ref);
```

#### Off-Heap Memory, Off-Host Memory

1. 사용자 별 메모리를 다루는 또 다른 효과적인 방법은 별도의 프로세스로 관리하는 것.
2. 서버 프로세스의 주소 공간 안에 위치시키는 대신, Memcached, Reids와 같은 독립적인 프로세스에 두는 것.
3. 물론, 트레이드 오프가 존재함. 다름 아닌 크기와 거리(성능). 더 많은 공간을 얻는 대신, 더 먼 거리에서 데이터를 주고 받음.

#### Sockets

1. 서버의 소켓 갯수 또한 트래픽이 무거워질 때 문제가 될 수 있음.
2. OS는 인바운드 연결을 수명이 짧은<sup>ephemeral</sup> 포트에 할당.
3. TCP 패킷 포맷을 들여다 보면, 포트 번호 길이가 16 비트임을 확인할 수 있음.
4. 따라서, 65,535개까지만이 가능. OS별로 다를 수는 있으나 IANA는 49,152에서 65,535를 권장한다고 함.
5. 하지만, 어떤 서버들은 동시에 백만개의 연결을 받아주기도 함.
6. 이것이 가능한 이유는 가상 IP 주소 때문임.
7. OS는 추가 IP 주소들을 동일한 네트워크 인터페이스에 바인딩함.
8. 각 IP 주소는 자신의 고유한 포트 번호 범위를 가지며, 16개의 IP 주소가 있다면 위와 같은 많은 연결들을 받아줄 수 있게 됨.
9. 하지만, 이렇게 많은 연결을 허용하는 것이 쉬운 것은 아님. 애플리케이션에도 변화가 필요하며, 많은 커널 버퍼들이 필요함. OS의 TCP 튜닝 파라미터에 대해 많은 공부가 필요할 것.

#### Closed Sockets

1. 소켓을 여는 것도 문제가 될 수 있지만, 이미 닫힌 소켓 또한 문제가 될 수 있음.
2. 애플리케이션 코드에서 소켓을 닫으면, TCP 스택은 소켓을 두 개의 상태를 거치게 하는데, 그 중의 하나는 TIME_WAIT.
3. 이는 소켓이 새로운 연결에 재사용 되기 전 유예 기간 같은 것이며, bogons에 대한 TCP 방어책 중 하나.
4. bogons란, 비효율적으로 라우팅 되어 늦게 도착하는 방황하는 패킷을 가리킴.
5. 소켓이 너무 빨리 재사용되면, 이렇게 늦게 도착한 패킷이 마치 새로 시작하는 정상적인 패킷 처럼 여겨질 수도 있음.
6. [bogons](https://en.wikipedia.org/wiki/Bogon_filtering)이 실제로 발생하는 문제이긴 하지만, 이슈가 될 가능성은 매우 낮으며, 따라서 TIME_WAIT 인터벌을 낮출 수도 있음.

### EXPENSIVE TO SERVE

1. 단지 읽기만 하고 나가는 사용자에 비해, 실제로 물건을 장바구니에 담고 결제를 하는 등의 연동 포인트나 쓰기를 발생시키는 고객들이 존재. 책에서는 expensive user라고 부름.
2. 수익에 도움이 되는 고객이긴 하지만, 시스템에 부하를 주는 것도 사실. 어떻게 다루는 것이 좋을까.
3. 가장 좋은 방법은 공격적으로 테스트 하는 것.
4. 가장 비용이 큰 트랜잭션을 파악하고, 평소 대비 2~3배의 트랜잭션을 만들 것.
5. 만약, 시스템이 2퍼센트의 전환률을 예상한다면, 4~10퍼센트 정도의 전환률을 테스트 하는 것.

### UNWANTED USERS

1. 이상한, 나쁜 고객들은 존재한다.
2. 쿠키 값을 비워둔 채, 응답을 기다리지 않는 수 십만 개의 요청을 동시에 보낼 수도 있음. 마치 새로운 사용자가 요청을 던지는 것 처럼 보여질 수 있고, 서버에서는 요청 마다 새로운 세션을 생성하기도 함. 또한, 세션 생성 시 '마지막 로그인' 시간 같은 것을 매번 갱신하게 할 수도 있음. 부하가 더 커지는 것.
3. 악의적인 요청들도 만들 수 있음(스크린 스크래퍼). 마치, 경쟁 식료품 가게가 옆 가게에 악의적 손님들을 줄을 세워서, 정상정인 손님들이 가게 안으로 못 들어가게 하는 것 처럼 말이다.
4. 스크린 스크래퍼 같은 것을 막는 방법으로, 네트워크에 이런 요청을 가려내 차단하게 하거나, 법적 조치를 취하기도.

## Blocked Threads

1. 멀티스레딩은 많은 처리를 동시에 할 수 있게 해주었지만, 동시성 오류의 가능성을 가져왔음.
2.  필자가 겪은 대부분의 시스템 장애는 명백한 충돌이라기 보다는, 프로세스는 실행중이지만 프로세스들이 아무 것도 하지는 않는 상태였음.
3. 하지만 사용자 입장에서는 똑같은 문제. 어쨋든 사용자가 아무 것도 할 수 없기 때문임. 비즈니스 스폰서 입장에서는 "Is it generating revenue?"라고만 물을 뿐임.
4. 이 때문에 외부 모니터링과 함께 내부 모니터링도 필요하다고 주장. 목<sup>mock</sup> 클라이언트를 만들어 실제 사용자가 수행하는 트랜잭션들을 주기적으로 확인해 보게 할 수도 있음. 프로세스가 실행중이냐 여부와 상관 없이, 사용자가 겪을 수 있는 문제를 조기에 드러낼 수 있음.
5. 스레드 잠김(잠시 동안의 잠김은 문제 없음. 오히려 자연스러움)은 어려운 문제이고, 테스트로도 발견하기 어려움. 가장 좋은 방법은 신중하게 코드를 작성하는 것. 잘 작성되고 입증된 라이브러리를 사용하는 것도 좋음.
6. 여러 가지 이유로 도메인 객체에 synchronize를 사용하는 것도 반대. 대신, 도메인 객체를 불변으로 만들라고 권장함. 질의와 렌더링에 사용하는 것. 상태를 변경해야 한다면, 커맨드 객체에게 위임. CQRS라고도 불림.

#### SPOT THE BLOCKING

```java
String key = (String) request.getParameteR(PARAM_ITEM_SKU);
Availability avl = globalObjectCache.get(key);
```

1. 위 코드에서 블럭킹 호출을 찾을 수 있겠는가?
2. `globalObjectCache`가 동기화가 있을만한 지점이라고 추측했을지도 모르지만, 여기서 중요한 것은 호출 코드에서는 어디가 블럭킹 지점인지 결코 알 수 없다는 것.
3. 자바에서는 synchronized 메소드를 unsynchronized로 바꾸기 위해 클래스를 상속할 수도 있음. 리스코프 치환 원칙에 위배되기도 함.

```java
public class GlobalObjectCache {
    // ...
    public synchronized Object get(String id) {
        Object obj = items.get(id);
        if (obj == null) {
            obj = create(id);
            items.put(id, obj);
        }
    }
    // ...
}
```

4. 어쨌든 `GlobalObjectCache#get`에는 synchronized가 걸려 있음.
5. 이를 사용하는 시스템에서는 재고 관리가 필요했음. 재고 정보는 원격 호출로 가져오고, 15분 단위로 원격 시스템에서 재고 수치를 갱신.
6. 재고 호출량이 많기 때문에, 호출자는 캐싱을 도입하기로 함.
7. 캐싱 도입을 위해 `GlobalObjectCache`를 상속하는 `RemoteAvailabilityCache`를 만들고, create 부분을 원격 호출하는 코드로 대체.
8. 기능적으로 문제가 없었으나 부하가 심한 경우 원격 호출이 대기하게 됐고, synchronized와의 조합으로 수 많은 호출부가 대기하게 됨.
9. 결과적으로 전체 사이트가 다운 됨. 단지, 원격 재고 시스템이 안 된다는 이유 때문에 말이다. 재고를 불러올 수 없다고 전체 시스템이 마비되어야 할까?

#### LIBRARIES

1. 라이브러리는 스레드 잠김의 단골 손님. 오픈소스이건 벤더 코드이건.
2. 많은 라이브러리들은 자신의 리소스 풀링을 위해 마치 서비스 클라이언트 처럼 동작함. 이것이 영원히 스레드가 잠기는 문제의 원인이 됨.
3. 또한, 이런 라이브러리들은 자신들의 실패 모드에 대한 설정을 제공하지 않음.
4. 여기서 벤더 코드에 대한 비판이 또 나옴. 기록은 생략.
5. 라이브러리가 깨지기 쉽다면, 요청을 다루는 스레드를 우리가 보호할 수 있어야 함.
6. 그렇지 않다면 적어도 퓨처를 반환하는 래퍼 클래스로 라이브러리를 감싸는 것이 좋음. 그리고 이 래퍼 클래스들을 사용할 수 있는 스레드 풀을 관리하라는 이야기. 타임아웃도 래퍼 클래스를 통해 제공하고 말이다. Hystrix의 [`execution.isolation.strategy`](https://github.com/Netflix/Hystrix/wiki/configuration#executionisolationstrategy)를 같이 보면 더 좋을 듯.
7. 이런 블럭 스레드는 통합 지점에서 주로 발견되며, 연쇄 반응으로 이어지기 쉽상. 또한 피드백 루프를 만들며 사소한 문제가 전체 장애로 확장되기도.

#### REMEMBER THIS

원래 이 항목은 기록하지 않았는데, 아래 내용이 인상 깊어서 특별히 기록함.

> All manner of problems can lurk in the shadows of third-party code. Be very wary. Test it yourself. Whenever possible, acquire and investigate the code for surprises and failure modes. You might also prefer open source libraries to closed source for this very reason.

## Self-Denial Attacks

1. Self-Denial Attack을 어떻게 번역해야 할지 모르겠음.
2. 어쨌든 책에서 소개하는 이 단어의 정의는 다음과 같음.

> A self-denial attack describes any situation in which the system-or the extended system that includes humans-consipires against itself.

3. 스스로를 망가뜨리는 상황을 이야기하는 것이고, 대량의 트래픽이 몰릴 수 있게 마케팅을 하는 등의 행위를 가리킴.
4. 트래픽이 몰리는 경우를 대비하는 방법으로 (어떻게 보면 당연한) "shared-nothing" 아키텍처 구성도 언급함. 다소 뜬금 없긴 하지만, 대량 트래픽이 몰리는 경우 공유 자원에 의해 잘못된 잠금을 경험했기 때문에 언급하는 것으로 보임.
5. 또한, 하드웨어 로드 밸런싱을 구성하고, 요청이 몰리는 시스템의 나머지에 대해서는 정상적으로 응답하게 할 수도 있음. 미리 이벤트 상품 전용 서버를 구축할 수도 있음.
6. 오토 스케일링 시에는 "pre-autoscale"을 권장한다는 이야기도.
7. 교육과 훈련, 커뮤니케이션의 중요성도 함께 언급. (별 것 아닌 것 같지만 제일 효율적인 수단이라고 생각함)

## Scailing Effects

1. [Square-Cube Law](https://en.wikipedia.org/wiki/Square%E2%80%93cube_law). 코끼리 크기의 거미가 왜 나올 수 없는지를 설명하는 이론. 크기가 커질 수록 몸무게는 부피에 비례해서 늘어남. 즉, O(n^3). 하지만, 다리의 길이는 길어지기만 할 뿐이라서 O(n^2). 지탱할 수 있는 다리의 힘이 몸무게가 늘어나는 속도를 따라잡을 수 없음.
2. 스케일링에도 비슷한 문제가 있음. 다대일이나 다대소수 관계에서가 그러함.
3. 개발에서는 1개의 장비를, QA에서는 1개나 2개의 장비를 사용하지만, 프로덕션에서는 일부 애플리케이션은 매우 작은 반면, 어떤 것은 매우 거대함. 개발이나 QA 단계에서 이 크기를 재현하지 않는 것이 대부분. 스케일링에 따른 문제를 발견할 수 없는 이유가 됨.

### POINT-TO-POINT COMMUNICATIONS

먼저, 점대점 통신이 가지는 문제에 대해.

1. 점대점 통신에는 각 인스턴스들이 다른 인스턴스들과 직접 통신함.
2. 전체 연결의 수는 인스턴스 수의 제곱이 됨. O(n^2).
3. 인스턴스 수가 많아질 수록, 테스트 환경에서는 발견할 수 없는 문제를 프로덕션에서 발견할 가능성이 높아짐.

이를 해결하기 위한 방법들.

1. 구글이나 마이크로소프트가 아닌 이상에야, 테스트 환경을 유사하게 구축하기는 어려움.
2. 테스트 보다는 설계로 해결해야 함. 점대점 통신을 아래의 것들로 바꾸는 것을 고려해 볼 수 있음.
3. UDP 브로드캐스팅을 고려. 대역폭 사용이 비효율적.
4. TCP 또는 UDP 멀티캐스팅을 고려. 좀 더 효율적. 브로드캐스팅에 비해 오직 관심 있는 서버에 대해서만 메시지 수신을 허용하기 때문.
5. 구독/수신 메시징을 고려. 좀 더 나은 선택. 서버가 잠시 고장나더라도, 정상화 된 후에 다시 메시지를 주워갈 수 있기 때문. 하지만, 적지 않은 인프라 비용이 수반되며 "Do the simplest thing that will work"을 생각해 볼 필요가 있음.
6. 메시지 큐도 고려.

### SHARED RESOURCES

1. 공유 자원은 수평 확장된 레이어의 모든 멤버들이 사용하는 기능이나 서비스를 가리킴.
2. 클러스터 매니저나 락 매니저 등이 여기에 해당함.
3. 이곳에 부하가 생기면 수용량을 제한하는 병목이 되기 쉽상.
4. 물론, 반독점적이면서 자원이 충분하다면 문제가 되지 않음. 한계에 도달하더라도 늘리면 됨.

## Unbalanced Capacities

수용력에 불균형이 있을 수 있음.
1. 예를 들어, 프론트 시스템이 존재하고, 여기서 모든 요청을 먼저 받은 다음, 뒤에 있는 스케쥴링 시스템과 상품 검색 시스템으로 요청을 분배해준다고 해보자.
2. 평소에는 대부분의 요청이 상품 검색으로 가지만, 마케팅이나 프로모션 등에 의해 스케쥴링 시스템으로의 요청이 평소 대비 10배 이상 뛸 수도 있음.
3. 그러나, 스케쥴링 시스템은 이 부하를 다 처리할 준비가 되어 있지 않을 수도.
4. 그렇다고, 예상 가능한 최대 부하를 견디도록 인프라를 설계할 수도 없는 일. 대부분이 유휴 시간일테니.

예상 가능한 부하를 감당할 수 있을 만큼 시스템을 크게<sup>large enough</sup> 설계하는 대신, 호출부나 제공자 모두 요청의 쓰나미에 맞춰 탄력 있게<sup>resilient</sup> 만들 것.

1. 호출자의 입장에서는 Circuit Breaker가 다운스트림 서비스에 대한 압력을 경감시켜 준다는 점에서 도움이 될 것.
2. 서비스 제공자의 입장에서는 Handshaking과 Backpressure를 통해 호출자에게 요청량 조절<sup>throtle</sup>을 안내할 수도 있음.
3. 또한, 우선 순위가 높은 요청이나 중요한 서비스에 대한 수용력을 보존하기 위해 Bulkhead를 고려할 수도.

### DRIVE OUT THROUGH TESTING

1. 수용력 불균형 또한 마찬가지로 QA에서 발견되기 어려운 문제.
2. 1:1 정도로 프론트엔드와 백엔드를 구성하기 때문. 하지만, 프로덕션에서는 10배 이상 차이날 수도 있음.
3. 동일한 스케일 아웃을 QA에 구성하기는 어려운 일. 대신, Test Harnesses(뒤에서 다루는 주제)를 적용하자.
4. 한편, 예상할 수 없는 트래픽의 변동에 대해서도 준비해야 함.
5. 첫 번째 이야기는 이해 안 됨. 영어로 그대로 가져옴. "First, use capacity modeling to make sure you're at least in the ballpark. Three thousand threads calling into seventy-five threads is not in the ballpark."
6. 두 번째로, 부하 상황을 테스트 할 것. 시스템이 충분히 탄력적이라면 조금 느려지다가(혹은 빠른 실패를 하거나), 부하가 사라지면 다시 원래대로 복구돼야 함.
7. 세 번째로, 오토 스케일링을 사용 권장.

## Dogpile

> When a bunch of servers impose this transient load all at once, it's called a dogpile. ("Dogpile" is a term from American football in which the ball-carrier gets compressed at the base of a giant pyramid of steroid-infused flesh.)

1. 소프트웨어에서의 장애를 대규모 정전에 비유.
2. 전력 수요의 급증은 정전을 만들어 낼 수 있고, 다시 복원되자마자 전력 사용량은 엄청나게 복원된 장비로 몰려들 것. 그럼 다시 부하가 생기고 정전이 되는 일이 반복.
3. 지금은 전력 공급 장애에 대한 대비가 잘 되어 있음.
4. 이로부터 배울 수 있는 교훈 한 가지는 실제와 동일하게 복잡한 상황(모터, 전송 라인, 전력 차단기, 전력 생성기, 제어 시스템, ...)에서야 문제를 재현할 수 있다는 것. 이 중 일부만 구성해서는 재현이 어려울 수도.
5. 또 다른 교훈 한 가지는 정상 상태에서의 부하는 초기 구동 시나 주기적인 부하와는 완전히 다르다는 것. 콜드 캐시, 수 많은 시드 데이터 초기화, 데이터베이스 연결 등을 생각해 보면 됨.
6. 이로 인한 도그파일은 서버가 재시작 되거나, 정오에 크론 잡이 실행되거나, 설정 관리 시스템이 변경을 알려주거나 하는 등의 경우에 얼마든지 발생 가능.
7. 일부 설정 관리 도구들은 무작위 "slew"를 지원. 변경사항을 조금씩 서로 다른 시간 대에 끌어가게 하는 것. 몇 초에 걸쳐 도그 파일의 위험을 분산시키는 것.
8. 부하 테스트를 할 때도 일정 주기로 부하를 멈추게 하는 대신 무작위를 권장.

## Force Multiplier

Force Multiplier는 지렛대처럼, 운영자에게 적은 노력으로 많은 것들을 할 수 있게 해주는 자동화를 가리킴.

### OUTAGE AMPLIFICATION

2016년에 Reddit.com에 장애가 발생. 포스트 모텀에서 레딧 운영자는 의도적인 수동 변경 사항과 자동화된 플랫폼 사이의 충돌에 의한 문제였음을 설명.

1. 운영자는 잠시 오토스케일링 서비스를 중단. 주키퍼 클러스터를 업그레이드 하기 위해.
2. 업그레이드 프로세스가 진행되는 사이, 패키지 관리 시스템은 오토스케일러가 죽은 것을 발견하고 재시작 시킴.
3. 오토스케일러는 다시 온라인 상태가 되고 일부만 마이그레이션 된 주키퍼 데이터를 읽어 들임. (현재 실행중인 것 보다 훨씬 작은 규모의 환경이라고 인식함)
4. 오토스케일러는 너무 많은 서버가 실행중이라고 판단하고, 많은 애플리케이션과 캐시 서버를 중단시킴. 다운타임의 시작.
5. 운영자는 오토스케일러가 문제 원인임을 인지한 뒤, 오토스케일러를 오버라이딩 하고 인스턴스들을 복구하여 수동으로 시작시킴. 인스턴스들은 돌아왔지만 캐시들은 비어 있음. 모든 요청들이 동시에 데이터베이스에 질의를 던지게 됐고, 데이터베이스의 도그파일을 일으킴. 레딧에 접속은 되지만 느려서 쓰기가 어려운 상태.
6. 캐시가 충분히 구워지고 난 뒤에야 서비스 정상화.

이와 같은 문제가 서비스 디스커버리 시스템에도 일어날 수 있음.

1. 디스커버리 시스템은 등록된 서비스들이 무엇인지 동기화하기 위해, 자신들끼리 서로 통신함. 가십 프로토콜을 사용해서 그런지 모르겠지만 책에서는 시스템들끼리 gossip 한다고 표현하고 있음.
2. [여기 그림](https://www.safaribooksonline.com/library/view/release-it-2nd/9781680504552/images/stability_antipatterns/force_multiplier_service_discovery_partitioned.png)에서와 같이, 특정 디스커버리 서비스 노드가 서비스들과의 네트워크가 단절될 수 있음.
3. 이로 인해, 디스커버리 노드는 모든 서비스가 이용 불가하다고 판단.
4. 이 판단을 다른 디스커버리 노드에게 전달.
5. 결과적으로 모든 디스커버리 노드들도 모든 서비스가 이용 불가하다고 판단하게 됨.

"원하는" 상태가 잘못 계산되었으며, 이 계산 결과가 현실적으로 불가능한 상태라면, 장애는 얼마든지 발생할 수 있음.

### CONTROLS AND SAFEGUARDS

OSHA(Occupational Safety and Health Administration)라는 조직이 있음. 로봇에 대한 여러 안전 충고를 내는 기관. 이 충고들로부터 "control plane"류의 소프트웨어(사용자 기능을 직접 제공하기 보다, 로깅, 모니터링, 스케쥴러, 스케일러, 로드 밸런서 등과 같이 인프라나 애플리케이션을 관리하기 위한 도구들을 일컬음)들 또한 배울 수 있는 것들이 많음.

1. 시스템의 80퍼센트 이상이 이용 불가하다고 보고된다면, 시스템 자체 보다는 보고자(관찰자)의 문제일 가능성이 큼.
2. Apply hysteresis. 장비의 시작은 빠르게 하고, 중단은 천천히 하라. 새로운 장비를 시작하는 것이 중단시키는 것 보다 안전함.
3. 기대하는 상태와 발견된 상태 사이의 간극이 너무 크다면, 확인을 위한 절차를 두자.
4. 리소스를 소비하는 시스템들은 충분히 stateful 해야 함. 무한한 인스턴스들을 구동시키려고 하는 것인지 감지할 수 있을 만큼.
5. 감속 구간을 만들자. 여러분의 control plane이 부하가 초과함을 감지했으나, 가상 장비를 시작시키는 데 5분이 걸린다고 가정해 보자. 감속 구간이 없다면 300개 이상의 가상 장비를 재시작 시킬지도 모름.

### REMEMBER THIS

Force Multiplier도 좀 더 기억에 남기고자, 원래는 기록하지 않는 REMEMBER THIS를 정리.

Ask for help before causing havoc.

1. 인프라 관리 도구는 단시간에 지대한 영향을 미칠 수 있음.
2. 전체 시스템이 한 번에 붕괴되지 않도록,
3. 제한자<sup>limiters</sup>와 안전보조장치<sup>safeguards</sup>를 마련.

Beware of lag time and momentum.

1. 자동화에 의한 액션이 시작되는 데는 시간이 걸릴 수 있음.

2. 보통 이 시간은 모니터링 주기보다 길기 마련.

3. 따라서, 시스템이 액션을 취하는 데 걸리는 지연을 감안하게 할 것.

Beware of illusions and superstitions.

1. 제어 시스템은 기대하는<sup>exepected</sup> 상태를 계산함.
2. 또한, 현재<sup>current</sup> 상태에 대한 "믿음"(현재 상태에 대한 파악은 정확하지 않을 수 있음을 표현하는 것)을 계산함.
3. 두 결과 모두 잘못될 수 있음을 인지해야 함.

## Slow Responses

1. 앞에서 살펴본 것처럼, 느린 응답은 연결 거부 또는 에러 응답보다 안 좋음. 중간 레이어 서비스인 경우 특히 더 그러함.
2. 느린 응답은 주로 과도한 수요에 의해 발생.
3. 모든 요청 핸들러가 일하고 있다면, 더 이상의 새로운 요청을 받을 수 없음.
4. 느린 응답은 또한 또 다른 내재된 문제의 증상일 수도.
5. 메모리 누수는 종종 느린 응답의 형태로 나타남. (가상 머신이 트랜잭션 처리를 위한 메모리를 얻기 위해 점점 더 열심히 일하기 때문)
6. 높은 CPU 사용량으로도 나타날 수도 있으나, 가비지 컬렉션 때문이지, 트랜잭션 처리 자체를 위한 작업 때문은 아님.
7. 때로는 네트워크 정첼 인해 느린 응답이 만들어지기도 함. LAN 안에서는 보기 드문 일이지만, WAN에서는 분명히 발생할 수 있는 문제. 잦은 통신을 하는 프로토콜 일수록 더더욱.
8. 소켓의 전송 버퍼를 빈 상태로 유지하며 수신 버퍼를 꽉 채우는 바람에 TCP 정지가 발생하는 경우는 자주 봄. 저수준에서 직접 소켓 프로토콜을 다룰 때 많이 발생하며, 수신 버퍼가 빌 때까지 읽기 루틴이 루프를 돌지 않는 경우에 이 문제가 발생.
9. 느린 응답은 상위 레이어로 전파되는 경향이 있음.
10. 당연한 얘기지만, 애플리케이션 성능을 모니터링할 수 있어야 하며, SLA 위반을 인지할 수 있어야 함.

## Unbounded Result Sets

1. 대부분의 애플리케이션들은 데이터베이스를 지나치게 신뢰함.
2. 일반적인 데이터베이스 질의 코드는 다음과 같음.
3. 데이터베이스에 질의 전달 → 결과 셋에 대해 루프를 돌며 → 각 로우를 객체로 변환
4. 데이터베이스가 갑자기 5만 개의 로우를 반환한다면 어떻게 될까?
5. 메모리 고갈이 일어나거나, 사용자가 이미 관심을 잃은 상태에도 여전히 오랫동안 루프를 돌고 있을 것.
6. 아래 내용이 계속 반복되는 내용이지만 그럼에도 불구하고 인상 깊음.

> Design with skepticism, and you will achieve resilience. Ask, "What can system X do to hurt me?" and then design a way to dodge whatever wrench your supposed ally throws.

### BLACK MONDAY

1. 저자가 맡은 커머스 서비스에서 장애가 발생.
2. OOM이 일어나고 CPU는 높았으며, 반복적으로 재시작을 해도 문제는 반복됐으며, 전체 인스턴스 중 정상적인 인스턴스의 비율은 1/4을 넘지 못함.
3. 수행 중인 쿼리들도 특별한 것이 없었으나, JMS 구현에 사용된 메시지 테이블을 사용한 쿼리가 문제였음.
4. 이 테이블은 전체 로우 수가 1,000개를 넘지 않아야 함. 하지만 이 테이블에 대한 쿼리가 가장 무거운 것들 중의 하나라고 DBA로부터 전달 받음.
5. 어떤 이유에서인지 1,000만 로우가 넘게 존재했음. 그리고 애플리케이션은 이 테이블로부터 전체 로우를 불러들이려 했음.
6. 게다가, "select for update" 쿼리를 던졌기 때문에 락이 발생.
7. 그리고 애플리케이션이 쿼리 응답 메시지로부터 객체를 추출하려고 하면 OOM이 발생.
8. OOM이 발생하면서 트랜잭션이 롤백되고, 다음 애플리케이션이 이 행위를 반복함.
9. LIMIT 절이 빠진 것을 보완하기 위해 어마어마한 일을 했고 그렇게 월요일은 끝나버림.
10. 왜 1,000만개의 로우가 들어가 있는지를 찾아내려는 것과 별개로,
11. 이것을 다 읽어들이려는 것 또한 독립적 문제.
12. unbounded 결과 셋이 발생하는 것은 호출자가 다른 시스템이 조건을 명시하는 것을 허용하게 할 때 발생함. 이는 핸드쉐이킹 실패.
13. 어떤 API나 프로토콜은 얼마만큼의 응답을 받을 수 있는지 항상 명시해야 함.
14. TCP는 "window"라는 걸 통해 이를 수행하고, 검색 엔진 API는 호출자가 몇 개의 결과를 받을지 offset과 함께 명시하는 것을 허용함.
15. 하지만, 표준 SQL 문법에는 그런 것이 없음. ORM에서 연관 관계를 불러올 때는 결과 갯수를 제한하는 파라미터를 지정할 수 없음. (전형적인 문제)
16. Unbounded 결과 집합은 느린 응답의 흔한 이유가 됨. *steady state*(뒤에서 다루는 주제)를 어겨서 발생하는 문제.

### REMEMBER THIS

인상 깊은 구절 2개만 기록.

> Don't rely on the data producers.

> Put limits into other application-level protocols.

# Stability Patterns

앞서 살펴봤던 시스템의 크랙들을 제거하거나, 영향 범위를 줄이거나 하는 등의 방법들에 대해 살펴볼 예정. QA를 통과하게 하지는 못하지만, 꿀잠을 잘 수 있게 해주고, 가족들과의 저녁 식사가 방해받지 않을 것. 다만, 유의할 것은 "Count of patterns applied"는 좋은 지표가 되지 못한다는 것. 시스템이 안정성을 갖추는 것이 중요.

## Timeouts

지금은 모든 시스템이 분산 시스템. 네트워크는 종종 실패하고, 애플리케이션은 이런 특성을 대비할 수 있어야 함. 와이어, 스위치, 라우터, 그리고 우리가 다루는 컴퓨터 또한 부서지기 쉬움. 이 때, 언제 돌아올지 모르는 응답을 마냥 기다릴 수는 없음. 희망을 버리고 포기할 수 있어야 함. 잘 적용된 *timeout*은 장애 격리를 가져다 줌. 다른 서비스나 장비의 실패가 꼭 우리의 문제가 될 필요가 없음.

*timeout*은 광범위하게 적용되곤 하는데, 이를 다루는 방법들은 다양함. 먼저, 오래 걸리는 연산들을 기본 요소 집합으로 만들어서 많은 곳에 재사용.

1. 예를 들어, 데이터를 DB로부터 가져오는 일련의 작업.
2. 리소스 풀로부터 DB 연결을 체크아웃하고, 쿼리를 실행하고, 결과를 객체로 변환하고, DB 연결을 다시 풀로 반환.
3. 이런 일련의 과정을 모든 곳에 반복해서 작성하는 대신, [Query Object(P of EAA catalog)](https://martinfowler.com/eaaCatalog/queryObject.html)를 적용.

또한, 제너릭 게이트웨이를 사용해서 템플릿을 제공할 수도.
1. 호출부는 핵심 로직을 이 템플릿을 통해 실행.
2. 이런 식으로 하면 Circuit Breaker 패턴 적용도 쉬워짐.

플랫폼을 최대한 활용할 수도 있음.
1. Amazon API Gateway 같은 서비스는 우리를 대신해서 여러 지저분한 일들을 대신 처리해 줌.
2. 콜백이나 리액티브 프로그래밍 같은 도구들은 *timeout*을 쉽게 지정할 수 있게 도와줌.

*timeout*과 더불어 재시도를 사용할 때는 느린 재시도도 함께 고려.

1. 보통 빠른 재시도를 시도하기도 하지만,
2. 장애는 얼마간 지속되기 마련이고,
3. 따라서, *timeout* 이후의 빠른 재시도 역시 실패할 가능성이 매우 높음.
4. 반면, 느린 재시도를 위해 작업을 큐에 쌓는 것은 시스템을 더 강건하게 만들 수 있음.
5. 즉, 지연된 재시도를 함께 고려하자.

*timeout*은 Circuit Breakers와 잘 어울림.

1. *timeout*을 도표화 할 수 있고,
2. 많이 발생한다면 "off" 상태로 만들 수도.

*timeout*과 빠른 실패는 모두 레이턴시 문제를 다루는 패턴.

1. 빠른 실패가 들어온 요청에 적용되고,
2. *timeout*은 요청을 보내는 경우에 적용.

참고로, *timeout*은 또한 무한한 결과 셋에 대한 대응이기도 함. 하지만, 그리 효과적인 것은 아님. 임시 방편 정도.

### REMEMBER THIS

1. Apply Timeouts to Integration Points, Blocked Threads, and Slow Responses.
2. Apply Timeouts to recover from unexpected failures.
3. Consider delayed retries.

## Circuit Breaker

전기 배선이 처음으로 주택 건설에 사용되었을 때 많은 사람들이 피해를 봄.

1. 사람들은 많은 기기를 회로에 연결했고, 전류에 저항이 생기기 시작하면, 전류의 제곱에 비례해서 열을 만들어 냄.
2. 이 열은 너무 뜨거워서 때때로 집을 태우기도 함.
3. 그래서 처음에는 전기 퓨즈라는 것을 사용.
4. 집이 불타기 전에 스스로 불타 버리는 것. 가장 먼저 실패하여, 전체가 실패하는 것을 막기 위한 방안.
5. 하지만, 이 퓨즈는 일회성이었으며, 구리 동전과 같은 크기였다는 것이 문제.
6. 지금은 *circuit breaker*가 사용되며, 집이 불타는 것을 막아줌.
7. 원리는 동일함. 초과 사용을 감지하고, 가장 먼저 실패하며, 회로를 연다.
8. 전체가 붕괴되는 것을 막아주는 것에 더해, 위험이 사라지면 다시 시스템이 전체 기능을 수행할 수 있도록 원상복귀 됨.

소프트웨어에서도 같은 기법을 사용할 수 있음.

1. 일반적인 "closed" 상태에서 *circuit breaker*는 평상시 처럼 연산을 수행.
2. 하지만, 일정 횟수 이상 실패가 일어나면 *circuit breaker*는 써킷을 "opens" 상태로 바꿈.
3. 이 상태에서는 진짜 연산을 실행시키지 않고 호출을 바로 실패 처리함.
4. 일정 시간이 지난 뒤, 연산이 다시 성공할 수 있는지 여부를 결정하기 위해 "half-open" 상태로 전환.
5. 그리고 나서 "open" 또는 "close" 상태로 완전히 상태 전이됨.

시스템의 세부 상황에 따라 장애를 서로 다른 유형으로 관리할 수 있음. 예컨대, 원격 시스템에 대한 호출 타임아웃은 연결 거부 오류보다는 낮은 임계치를 설정할 수도.

또한, 회로가 열린 상태에서라고 해도, 들어온 요청에 대해서는 뭔가를 해줘야 함.

1. 호출을 즉각 실패(예외를 던지는 등)로 처리할 수도 있고,
2. 폴백 전략을 취할 수도 있음.
3. 마지막으로 반환했던 정상 응답이나 캐싱된 값을 반환하거나,
4. 개인화된 응답보다는 일반화 된 대답을 반환하거나,
5. 1차 서비스가 실패했으니 2차 서비스를 호출하거나.

*circuit breaker*를 적용할 때는 시스템의 이해관계자가 함께 결정해야 함.

1. 시스템의 부하 상태에서 특정 기능을 자동으로 끄는 것.
2. 이는 비즈니스에 큰 영향을 미칠 수도 있는 부분.
3. 따라서, 시스템 이해관계자가 써킷이 열리면 무엇을 해야 할지를 함께 결정해야 함.
4. 재고를 파악할 수 없는 상황에서도 고객의 주문을 허용할까?
5. 신용 카드나 배송지 주소를 검증할 수 없다면 어떻게 할까?

"너무 많은 실패"가 뭔지에 대한 정의도 필요.

1. 보통 전체 실패 갯수 보다는, 일정 시간 동안 얼마나 많은 실패가 일어났는지가 중요.
2. 5시간 동안의 5번 실패 vs. 1분 동안의 5번 실패

*circuit breaker*의 상태는 운영자에게도 매우 중요함.

1. 상태가 얼마나 자주 바뀌는지는 문제를 인식하는 매우 중요한 지표.
2. 따라서, 상태는 로깅되어야 하고, 현재 상태에 대한 모니터링과 질의가 가능해야 함.
3. 더불어, 써킷을 직접 제어할 수 있는 방법도 제공되어야 함.

*circuit breaker*는 단일 프로세스 단위로 동작해야 함.

1. 서로 다른 프로세스 간에는 써킷의 상태가 공유되지 않아야 함.
2. 여러 인스턴스가 독립적으로 써킷 상태를 관리하는 것이 비효율적이긴 하지만,
3. 이 효율을 위해 프로세스 간 통신이 도입된다면,
4. 새로운 고장 가능성도 함께 도입되는 것.

*circuit breaker*는 통합 지점을 보호하고, 장애 전파를 막아주며, 불균형 수용량을 조절해주고, 느린 응답에 대응할 수 있게 해 줌. 주로 타임아웃과 밀접하게 관련되며, 실행 실패와는 별개로 관리됨.

## Bulkheads

*bulkhead*는 배의 파티션을 가리키는 용어.

1. 출입구를 닫으면 *bulkhead*는 물이 한 구역에서 다른 구역으로 넘어가는 것을 막아줌.
2. 특정 구역의 물 침투가 배 전체를 가라앉히지 않도록 함.

소프트웨어에도 마찬가지로 적용 가능.

1. 물리적 이중화는 가장 흔한 *bulkhead*의 한 형태.
2. 가상 머신의 이중화는 물리적 이중화만큼 강건하지는 않음.
3. 서로 다른 VM이 같은 물리 상자에 담겨 있을 수 있기 때문.
4. 한편, 서비스를 여러 독립된 서버 위에 구현할 수도 있음.
5. 채널 파트너들은 당일의 항공편 요금을 조회할 수 없더라도,
6. 고객들은 체크인을 계속할 수 있게 하는 것이 그 예.
7. 클라우드에서 인스턴스를 올린다면, 여러 서비스 구역으로 나눠야 함. (AWS를 예로 들면, 가용존과 리전)
8. FAAS를 쓴다면 심지어 각 함수 호출이 별개의 구획에서 실행.

간단한 그림을 통해 이해를 돕고 있음.

1. [여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/stability_patterns/bulkheads_hidden_linkage.png) 같은 구조에서는 Foo, Bar, Baz가 서로에게 미칠 수 있는 영향이 큼.
2. Foo가 어떤 문제로 인해 Baz에게 문제를 일으키면,
3. Bar 역시 영향을 받게 됨.
4. Bar 입장에서는 문제 원인을 찾는 것도 쉽지 않음.
5. 만약, Foo와 Bar가 엄격한 SLA를 지켜야 하는 중요한 시스템이라면,
6. [여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/stability_patterns/partitioned_system.png)에서와 같이 Baz를 2개의 구역으로 나누는 것이 더 안전.
7. 클라이언트들끼리의 숨겨진 연결을 끊어주는 것.

그 외에 다양한 수준에서의 *bulkhead*를 이야기.

1. 클라우드 시스템에서는 로드 밸런서를 통한 VM 격리도 가능.
2. 아마도 ALB를 이야기하는 듯.
3. 코어 별로 프로세스를 분리해서 바인딩 할 수도 있음.
4. 스레드를 몇 개의 그룹으로 나누어 서로 다른 함수를 할당하기도.
5. 예컨대, 어드민이 사용하는 스레드를 미리 할당해 둘 수도.
6. 요청을 다루는 모든 스레드가 점유 중이라고 해도,
7. 어드민을 통해 포스트 모텀 분석을 위한 데이터나,
8. 서버 중지를 요청하는 것도 가능.

### REMEMBER THIS

1. Save part of the ship.
2. Pick a useful granularity.
3. Consider *Bulkheads* particularly with shared services models.

## Steady State

시스템에 사람이 개입되면 언제든 "ohnosecond"를 겪을 수 있음. 적어도 릴리즈는 사람이 아닌 시스템에 의해 실행되어야 하며, "no fiddling"의 논리적인 극단은 불변 인프라스트럭처<sup>immutable infrastructure</sup>.

시스템이 매일 문제가 있지 않는 이상에야, 서버를 접속하는 주된 이유는 아마도 로그 파일을 정리하고 데이터를 퍼징<sup>purging</sup>하는 것. *steady state* 패턴은 리소스를 쌓는 메커니즘이 있다면, 리소스를 다시 정리<sup>recycle</sup>하는 메커니즘도 있어야 한다는 것.

### DATA PURGING

*purging*라고 해서 캐시 무효화를 의미하는 줄 알았음. 여기서는 시간이 지나면서 점점 쌓이는 데이터를 어떻게 정리할 것인가에 대한 이야기. 데이터가 쌓여가면서 나타나는 증상으로는 대표적으로 I/O 수치와 응답 지연의 증가가 있음. *data purging*은 번거로운 일이고 세세히 따져봐야 하는 일. 관계형 DB의 참조 제약을 지키면서, 또는 고아 없이 데이터를 지우는 것이 어렵기 때문. 고아가 있는 경우에도 애플리케이션이 정상적으로 동작해야 함. 추가적인 코드와 테스트가 필요하게 됨.

### LOG FILES

로그가 잘못된 위치(예컨대, 애플리케이션 디렉토리와 같은 곳에)에 쌓이거나, 중복으로 쌓이거나, 불필요한 데이터까지 쌓거나, 각 머신에 별개로 쌓이는 것은 문제. 잠깐 시간을 내어 로그 로테이트를 설정하고, Logstash 같은 도구를 이용해 로그를 중앙화하고, 언제든 모니터링하고 검색하고 인덱싱 할 수 있도록 하자.

### IN-MEMORY CACHING

메모리가 오랫동안 관리되지 않고 쌓여 있다면, 적은 메모리로 인해 안정성과 수용성이 위협 받음. 캐시를 사용할 때는 아래 2가지 질문을 던져보자.

1. 사용할 키는 유한한가 무한한가?
2. 캐시된 항목들은 변하는가?

사용할 키의 갯수에 제약이 없다면, 캐시 크기에는 제한이 있어야 하고, 캐시 무효화 같은 관리가 필요함. 가장 단순한 형태는 시간 기반의 캐시 비우기. LRU나 working-set 알고리즘 등을 사용할 수도.

### REMEMBER THIS

1. Avoid fiddling. 사람 개입을 줄이자는 것.
2. Purge data with application logic.
3. Roll the logs.

## Fail Fast

실패를 미리 알 수 있다면 빠르게 실패하는 것이 좋음. 호출자가 불필요하게 자원을 점유 당하지 않기 때문. 그런데 어떻게 실패를 미리 알 수 있을까?

첫 번째로, "resource unavailable" 종류의 문제가 있음. 로드 밸런서는 연결 요청을 받지만, 서비스 풀 안에 가용한 서버가 없을 수 있음. 이 때 바로 연결 거부 응답을 하는 것. 설정으로 연결 요청을 큐에 대기시키기도 하는데 이는 *fail fast* 위반. DB 연결이나 외부 서비스의 연결 등 모든 통합 지점에서, 서비스는 가용한 모든 연결과 *circuit breaker* 상태를 빠르게 확인하고, 하나라도 부족하다면 빠르게 실패를 응답할 수 있음.

두 번째로, 웹 애플리케이션에서는 서블릿이나 컨트롤러에서 기본적인 파라미터를 작업 시작 전에 확인한 뒤, 유효하지 않다면 바로 실패를 응답할 수 있음. 

### REMEMBER THIS

1. Avoid Slow Responses and Fail Fast.
2. Reserve resources, verify Integration Points.
3. Use for input validation.

## Let It Crash

1. 때때로, 시스템 수준의 안정성을 만드는 최선의 방법은 컴포넌트 수준의 안정성을 포기하는 것.
2. Erlang 세계에서는 "let it crash" 철학이라고 불림.
3. 예외 핸들러를 통해 실행 스택을 고치거나, try-finally 블럭을 통해 누수된 리소스나 메모리를 극복, ... 하지만 충분치 않음.
4. 에러 복구는 어렵고 신뢰할 수 없으며,
5. 따라서 깨끗한 초기 상태로 가능한 빨리 돌아가자는 것.
6. 모든 가능한 에러를 테스트할 수 없고 예상할 수도 X.
7. 하지만 에러는 반드시 일어남.
8. 결국, 회복할 수 있는 방법을 찾아야 함.
9. 단, "let it crash"가 잘 동작하려면 다음 4가지가 보장되어야 함.

### LIMITED GRANULARITY

1. 충돌은 격리된 공간에서 일어나야 함.
2. 나머지 시스템은 연쇄 실패로부터 보호되어야 함.
3. Erlang이나 Elixir에서 이러한 경계는 액터<sup>actor</sup>가 됨.
4. 런타임 시스템은 전체 OS 프로세스를 죽이지 않으면서 액터가 종료되는 것을 허용.
5. Java나 Scala 같은 다른 언어에서는 Akka 같은 라이브러리가 존재.
6. MSA에서는 각 서비스가 경계가 됨.

### FAST REPLACEMENT

1. 새로운 상태로 돌아가는 일은 가능한 빨라야 함.
2. 액터의 경우 재시작 시간은 마이크로세컨드 단위로 이뤄짐.
3. 호출자는 인지하기도 어려울 정도.

### SUPERVISION

액터나 프로세스가 충돌하면 어떻게 재시작 시킬 수 있을까?

1. 배시 스크립트를 통해 루프를 돌게 할 수도 있으나,
2. 액터 시스템은 재시작을 위해 계층형 트리의 슈퍼바이저를 사용함.
3. 액터가 종료되면 런타임은 슈퍼바이저에게 이를 알림.
4. 슈퍼바이저는 자식 액터를 재시작하거나, 자식 액터 전체를 재시작하거나, 스스로 충돌하는 것을 결정.
5. 슈퍼바이저가 충돌하게 되면, 런타임은 모든 자식들을 종료시키고, 슈퍼바이저의 슈퍼바이저에게 이를 알림.
6. 궁극적으로는 모든 브랜치를 재시작 시킬 수도.

### REINTEGRATION

"let it crash" 전략의 마지막 요소는 재통합. 액터나 인스턴스가 충돌이 나고, 슈퍼바이저가 재시작을 시켰다면, 새로 복구된 프로바이더에게 호출을 재개할 수 있어야 함.

1. 직접 호출하는 경우라면 *circuit breaker*를 두거나,
2. 로드 밸런싱 풀을 사용한다면 풀에 다시 합류시키거나.
3. 고정으로 할당된 VM은 로드 밸런서의 헬쓰 체크로 재통합.

## Handshaking

*handshaking*이란, 기기들 간의 통신을 적절히 조정하기 위한 신호를 가리킴.

1. EIA-232C와 같은 직렬<sup>serial</sup> 프로토콜은 수신자가 수신 받을 준비가 되었다는 것을 알려줌.
2. 아날로그 모뎀은 기기 간의 속도와 인코딩을 합의하기 위해 *handshaking*을 사용.
3. 앞서 소개했던 것처럼, TCP는 three-phase handshake.

HTTP는 *handshaking*을 위한 옵션이 별로 없음. 503 정도가 현재 통신할 수 없다는 일시적 상태를 알려줄 뿐. 클라이언트가 이 응답에 잘 대응하는가는 또 다른 이야기. 원격 프로시저 호출 기술들도 마찬가지로 *handshaking*에 약함. 

*handshaking*은 부하 상황에서 스스로를 보호할 수 있는 하나의 수단. HTTP 기반의 서버에서 *hadnshaking*을 유사하게 나마 만들 수 있는 방법은 로드밸런서를 이용하는 것. 헬스 체크를 통해 서버의 건강 상태를 확인하고, 문제가 있는 서버로는 요청을 전달하지 않는 것. *circuit breaker* 또한 임시방편이 될 수 있음.

### REMEMBER THIS

1. Create cooperative demand control.
2. Consider health checks.
3. Build handshaking into your own low-level protocols.

## Test Harnesses

통합 테스트의 어려움에 대해 이야기.

1. 한 가지 변경 때문에 전체 회사가 테스트에 참여해야 하거나,
2. 오늘날의 시스템은 서로 얽히고 섥히기에 변경 관리의 부담이 만만치 않음.
3. 보통 정상적인 경우의 기능 테스트에 그침.

하지만, 실패는 반드시 일어나고, 여기에 대비하는 한 가지 좋은 방법은 바로 *test harness*.

1. 이를 통해 저수준의, 그리고 실패하는 네트워크 API를 작성할 수 있음.
2. 바이트를 너무 빠르게 또는 천천히 보내거나,
3. 소켓 바인딩 후 단일 연결에 대해서는 서비스를 하지 않거나.
4. 단일 *test harness*로 이런 다양한 형태의 올바르지 않은 네트워크 행위를 만들어 낼 수 있음.
5. 저자가 사용하는 한 가지 방법은 포트 별로 각 상황을 만드는 것.
6. 10200은 연결만 허용하고 응답 X, 10201은 응답하되 `/dev/random`을 그대로 복사해서 응답, 20202는 연결을 허용하지만 바로 버림, ...
7. 그리고 애플리케이션 수준의 비정상 행위들을 만들어서 조합할 수도 있음. 책에서는 서브클래스를 만들어서 한다고 하는데, 실제로 보면 좋을 듯 함.

### REMEMBER THIS

1. Emulate out-of-spec failures.
2. Stress the caller.
3. Leverage shared harnesses for common failures.
4. Supplement, don't replace, other testing methods.

## Decoupling Middleware

점점 그늘 속으로 사라진 미들웨어의 위상을 언급하긴 하지만, 잘 사용한다면 시스템 간의 커플링을 낮출 수 있음을 이야기. 다른 시스템 호출에 대한 구체적인 지식을 몰라도 되게 해주므로. 또한, 발행-구독의 메시징 시스템을 사용한다면, 시간적 그리고 대상에 대한 의존성도 낮춰줌. 이는 재앙의 전파를 막아주기도 하고, 응답 속도의 향상도 가져다 줌. 하지만, 큐의 예외, 늦은 응답, 콜백, 가정, 결과적 일관성과 결과적 실패 등을 모두 고려해야 함. 이는 비즈니스적 고려도 필요하기도 한 일.

### REMEMBER THIS

1. Decide at the last responsible moment. 미들웨어와 관련된 선택은 쉽게 돌이킬 수 없는 결정이므로.
2. Avoid many failure modes through total decoupling. 잘 사용한 미들웨어는 결합도를 낮춰줌. 이는 응답 지연의 감소와 더불어, 장애 확산을 막아주는 효과를 주기도.
3. Learn many architectures, and choose among them.

