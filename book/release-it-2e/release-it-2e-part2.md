# Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space

새로운 사이트를 만들어서 운영하기 시작. 첫 추수 감사절은 잘 지나감. 다음 날인 블랙 프라이데이가 되었고, 시스템 모니터링 지표들을 살펴봄. 주문 수는 전날보다 늘었지만, 페이지 레이턴시는 여전히 250ms 이하를 유지하고 있었음. 그런데 어느 순간, 모든 DRP에 빨간색이 표기되고, DRP의 롤링 재시작은 즉각 실패하고 있었음. 아래는 그 당시의 몇 가지 증상.

1. 세션 수가 전날보다도 높음.
2. 네트워크 대역폭 사용량이 높았지만 한계치에 도달한 건 아님.
3. 애플리케이션 서버 페이지 레이턴시가 높음.
4. 웹, 애플리케이션, 데이터베이스 CPU 사용량은 매우 낮음.
5. 검색 서버(종종 우리의 범인이었던)는 잘 응답 중. 시스템 통계는 건강해 보임.
6. 요청을 다루는 스레드들이 모두 바쁨. 상당수의 스레드가 5초 이상 자신의 일을 처리하는 중.

사실, 페이지 레이턴시는 문제를 잘 드러내지 못했음. 오래 걸리는 것들은 타임아웃이 걸리고, 통계는 성공적으로 요청을 처리한 경우만을 계산한 결과이기 때문. (그렇다고 실패하는 응답을 포함하기도 어려움. 실패하는 요청은 일반적으로 성공한 경우보다 빠른 시간 안에 끝나기 때문. 잘못된 응답 지연을 만들어 내는 것은 마찬가지. 목적을 생각해 보자) 문제가 있다는 전화를 받은지 거의 90분이 지나고 있었음. SLA를 어기기 직전의 상황.

프론트엔드 애플리케이션 서버의 스레드 덤프는 다음과 같은 모습을 보여주고 있었음.

1. 일부 스레드가 백엔드 호출을 위해 바쁜 상태였고,
2. 대부분의 스레드는 백엔드 연결을 기다리는 중.
3. 백엔드에 대한 연결 리소스 풀에는 타임아웃이 X.
4. 백엔드가 응답을 주지 않으면 프론트엔드는 계속 기다려야만 하는 상황.

다음으로 주문 관리 시스템을 스레드 덤프로 확인.

1. 외부 연동 지점 호출에 450개의 스레드가 사용되고,
2. 나머지 스레드는 이 호출이 끝나기를 기다리는 중.
3. 이 외부 연동 지점은 배송을 위한 스케쥴링 서버.
4. 보통 4대의 인스턴스가 가동되지만,
5. 유지보수를 위해 휴일 동안 2대를 중단시켰으며,
6. 남은 인스턴스 중 1대는 알 수 없는 이유로 이상 동작을 보이고 있었음.

결국, [여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/case_study_living_space/scheduling.png)에서 보듯 시스템 크기의 큰 불균형이 발생했던 것. 그런데, 남아 있던 스케쥴링 서버가 1대였으면, 부하가 발생했을 텐데, 왜 모니터링이 되지 않았을까?

1. 알림을 받긴 했지만,
2. 평소에도 일시적인 CPU 스파이크 알림이 있었고,
3. 이 스파이크는 거짓 경보였기에,
4. 서버가 1대만 남아 생긴 부하 알림까지 무시하게 된 것.

여러가지 방법을 찾던 중, 문제가 생기면 커넥션 풀 관리 컴포넌트를 재시작(복구)하기로 함. 구체적으로는 커넥션 관리 컴포넌트의 `max` 프로퍼티를 적절히 설정하고, `stopService`와 `startService`를 호출하는 것. 책에서는 이게 *recovery-oriented computing*의 핵심 개념이라고 함. ROC 제안의 수준은 아니겠지만, 전체를 재시작하는 대신, 일부만 복구하는 것.

참고로, ROC 원칙은 다음과 같음.

1. Failures are inevitable, in both hardware and software.
2. Modeling and analysis can never be sufficiently complete. A *priori* prediction of all failure modes is not possible.
3. Human action is a major source of system failures.

# Foundations

## Networking in the Data Center and the Cloud

데이터 센터와 클라우드에서 네트워킹을 한다는 것은 단순히 소켓 열기를 넘어, 별도의 노력과 보안이 요구되는 것.

### NICS AND NAMES

호스트네임에 대한 오해들이 있음. *hostname*이 완전히 별개인 2가지로 정의될 수 있기 때문.

1. OS가 자기 자신을 인식하기 위해 사용하는 이름. 호스트네임과 "[default search domain](https://apple.stackexchange.com/questions/286395/what-does-the-search-domain-in-the-network-preferences-do)"이 합쳐져 FQDN(Fully Qualified Domain Name)이 됨.
2. 외부 시스템에 대한 이름. DNS 리졸브 대상.

이로 인해, 장비가 가진 FQDN이, DNS가 IP 주소를 위해 가지고 있는 FQDN과 같은 것인지를 보장할 수 없음. 예컨대, "spock.example.com"에 대한 장비의 FQDN 집합(?)을 가지면서, "mail.example.com"과 "www.example.com"과 같은 DNS 매핑을 가질 수 있음. 장비의 호스트네임은 장비 식별에 사용되는 반면, DNS 네임은 IP 주소 식별에 사용. 많은 유틸리티와 프로그램은 장비 스스로에게 할당한 FQDN을 합법적인 DNS 이름으로 간주.

그 외에도 다양한 복잡함이 존재. "DNS 네임 -> IP 주소"는 다대다 관계. 단일 장비는 다수의 NIC를 가짐(멀티호밍<sup>multihoming</sup>). 이더넷 포트, Wi-Fi, 루프백 NIC, ... 그리고 데이터 센터는 다른 목적으로 멀티호밍을 함. 관리와 모니터링을 위한 네트워크를 서로 분리하여 보안을 강화하는 것. 또한, 백업 같이 높은 트래픽이 필요한 네트워크와 프로덕션 트래픽을 분리하기도 함. [본딩과 티밍](https://zetawiki.com/wiki/%EB%B3%B8%EB%94%A9,_%ED%8B%B0%EB%B0%8D)도 언급.

### PROGRAMMING FOR MULTIPLE NETWORKS

다수의 인터페이스는 애플리케이션에도 영향을 미침. 언어들이 지원하는 "쉬운" 버전의 소켓 리스닝을 피할 것.

```
// 안 좋은 접근법
ln, err := net.Listen("tcp", ":8080")

// 좋은 접근법
ln, err := net.Listen("tcp", "spock.example.com:8080")
```

어떤 인터페이스에 바인딩을 할 것인지 결정하기 위해서는, 애플리케이션이 장비의 이름과 IP 주소들을 알아야 함. 멀티호밍 된 장비에서 `getLocalHost` 등의 호출은 서버 내부의 호스트네임에 대응하는 IP 주소를 반환. 또한, 로컬 네이밍 컨벤션에 따라 얼마든지 달라질 수 있음. 따라서, 소켓을 리슨해야 하는 서버 애플리케이션은 어떤 인터페이스를 바인딩할 것인지를 결정할 수 있도록 설정 가능한 프로퍼티를 제공해야 함.

## Physical Hosts, Virtual Machines, and Containers

모든 장비들은 어느 정도 공통점을 갖긴 하지만 서로 다른 부분도 많음. 물리적 데이터 센터 환경에서 잘 동작하는 설계가 컨테이너화 된 클라우드 환경에서는 많은 비용을 초래할 수도.

### PHYSICAL HOSTS

기록할 만한 내용 없음.

### VIRTUAL MACHINES IN THE DATA CENTER

가상화는 리소스를 효율적으로 사용할 수 있게 도와주지만, 종종 성능 문제를 야기함. `물리적 장비가 가진 리소스 < 물리적 장비 위에 올라간 가상화 장비들의 리소스 합`이 일반적이기 때문. 따라서, 가상화 장비에서 동작하는 애플리케이션은, 언제든 리소스 부족이나 성능 저하가 일어날 수 있음을 고려해야 함. 시계 문제도 언급. OS 시계는 믿지 않되, 실제 시간이 중요하다면 로컬 NTP 서버 같은 외부 소스를 사용.

### CONTAINERS IN THE DATA CENTERS

> “I’ll never again have to ask if production matches QA.”

컨테이너의 수명은 짧고, 따라서 인스턴스 기반의 설정은 피해야 함. 예컨대, Nagios 같은 오래된 모니터링 시스템은 장비가 추가되거나 재시작할 때마다 재설정이 필요. 또한, 로컬 저장소가 충분치 않음. 외부 스토리지 활용이 필요. 가장 어려운 부분은 네트워크 설정. 자주 사용되는 방법 중 하나는 *overlay network*를 구성하는 것. [Docker Guides의 Use overlay networks](https://docs.docker.com/network/overlay/) 함께 참고.

> The `overlay` network driver creates a distributed network among multiple Docker daemon hosts. This network sits on top of (overlays) the host-specific networks, allowing containers connected to it (including swarm service containers) to communicate securely. Docker transparently handles routing of each packet to and from the correct Docker daemon host and the correct destination container.

그 외에도 컨테이너의 *control plane software*(k8s, Mesos, Docker Swarm, ...), 설정 외부화(민감 정보, 호스트네임, 포트 등), 빠른 시작 시간(총 시작 시간이 1초가 되는 것을 목표로 하라고 함), 컨테이너 안에서 동작하는 디버깅의 어려움 등을 함께 언급.

### VIRTUAL MACHINES IN THE CLOUD

> Any individual virtual machine in the cloud has worse availability than any individual physical machine.

클라우드의 (데이터센터에 비해 상대적으로) 낮은 가용성, 자주 바뀌는 장비 ID와 IP 주소, 클러스터에 인스턴스를 투입하는 것이 컨트롤러에 의한 것이 아닌 인스턴스의 자원<sup>volunteer</sup>에 의해 이뤄져야 한다는 것, 기본적으로 제공되는 네트워크 인터페이스가 너무 간소화 되어 있다는 것(1개의 NIC와 비공개 IP 주소) 등을 언급.

### CONTAINERS IN THE CLOUD

클라우드 VM에 컨테이너를 올리는 것은 클라우드와 VM의 어려움을 함께 맞이하게 되는 것.

# Processes on Machines

이전 장에서는 소프트웨어가 배포되는 환경(다양한 네트워크와 물리적 장비)에 대해 알아봤다면, 이번에는 개별 인스턴스에 대해 이야기.  좀 더 구체적으로는, 코드, 설정, 연결<sup>connection</sup>에 대한 내용. 그 전에 몇 가지 용어 정리.

1. **Service** 일련의 기능을 제공하기 위해 협력하는 프로세스들의 집합. 서로 다른 *executable*로부터의 *process*로 구성될 수 있음. 예컨대, 애플리케이션 코드 + 데이터베이스.
2. **Instance** 단일 장비 위의 *installation*. *service*와 다르게, 같은 *execuatble*로부터의 *process*.
3. **Executable** 장비 위에서 *process*로 실행될 수 있는 artifact를 가리킴. 컴파일 언어에서는 바이너리, 인터프리터 언어에서는 소스.
4. **Process** 장비 위에서 실행되는 OS 프로세스. 
5. **Installation** 장비 위에 존재하는 *executable* + 부수적인 디렉토리 + 설정 파일 + 기타 리소스.
6. **Deployment** 장비 위에 *installation*을 만드는 행위.

별 것 아닌 것 같지만 이 정의는 중요하다고 함. "서버를 재시작 해"라고 했을 때, 우리는 무엇을 해야 한다는 얘기일까? 단어에 대해 서로 다르게 이해한다면, 단일 프로세스를 죽이라는 것인지, 혹은 전제 장비를 말하는 것인지 확신하기 어려움.

다시 돌아와서, 이제부터 인스턴스가 필요로 하는 코드, 설정, 커넥션에 대해 알아볼 예정.

## Code

### BUILDING THE CODE

개발자의 코드가 프로덕션 인스턴스까지 가는데, 강한 "일련의 보호<sup>chain of custody</sup>"가 필요. 허가되지 않은 누군가가 시스템에 코드를 넣는 일은 금지되어야 함.

일단 개발자의 코드는 VCS를 통해서 관리. 의존성 없이, 오직 코드만이 VCS로 들어감. 다음으로, 의존성을 인터넷으로 받는 것은 위험. 몰래 의존성이 대체될 수도 있고, 업스트림 저장소가 공격 받은 상태일 수도. 인터넷 상으로 받았다고 하더라도, 가능한 비공개 저장소로 옮겨야 함. 전자 서명이 업스트림 제공자의 정보와 매치되는 라이브러리만 이동시켜야. 빌드 시스템 플러그인 같은 것도 신뢰 X. 젠킨스 플러그인 사례도 언급. 개인 컴퓨터가 아닌, CI 서버를 통해 프로덕션 빌드를 하고, 아무나 쓰기를 할 수 없는 안전한 저장소에 바이너리를 관리하라.

### IMMUTABLE AND DISPOSABLE INFRASTRUCTURE

[여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/design_for_production/layers_of_stucco.png)처럼 기존 이미지에 계속 변경을 추가하기보다, [여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/design_for_production/start_from_known_state.png)처럼 known base image로부터 매번 새로 시작하라고 이야기. 기존 것은 버리고<sup>disposable</sup>, 새로 만들어서 사용하는 불변<sup>immutable</sup> 인프라를 구축.

## Configuration

### CONFIGURATION FILES

설정의 "starter kit"은 인스턴스 기동 시 읽어들이는 파일 집합. 동일한 소프트웨어가 여러 서버 인스턴스에서 동작하므로, 일부 설정들은 장비마다 다를 수 있음. 바이너리가 환경 별로 다른 것을 원하지는 않을 것. 따라서, 프로퍼티 파일이 환경 별로 다를 수 밖에 없고, 이는 VCS에서 설정을 분리해야 하는 한 가지 이유가 됨. 설정 파일에서 민감 정보를 분리해야 하는 것도 중요한 이유.

그렇다고 설정을 아예 VCS에 두지 말라는 것은 아님. 적어도 다른 저장소에서 관리. 접근 권한을 관리하면서 말이다.

### CONFIGURATION WITH DISPOSABLE INFRASTRUCTURE

EC2나 컨테이너 플랫폼 같은 이미지 기반의 환경에서는 설정 파일을 인스턴스 별로 다르게 가져갈 수 없음. 애플리케이션 시작 시 설정을 주입하거나, 설정 서비스를 활용해야 함.

EC2는 텍스트 블럽을 통해 사용자 데이터를 넘겨줄 수 있게 함. 한편, Heroku는 환경 변수를 선호. 이를 활용해 애플리케이션 시작 시 설정을 주입. ZooKeeper나 etcd 등의 설정 서비스를 이용할 수도. 애플리케이션은 이 서비스에 설정을 질의. 다만, 이 방식은 설정 서비스에 대한 의존도를 낳고, 따라서 설정 서비스의 다운 타임은 "심각도 1" 문제가 됨. 또한, 가용성 확보를 위해 네트워크 토폴로지를 잘 구성해야 하고, 실제로 운영 가용성도 매우 높아야 함. ZooKeeper는 스케일 가능하지만 엘라스틱하지는 않음. 따라서 노드 추가/삭제가 쉽지는 않고, 따라서 높은 수준의 운영 성숙도가 필요하고 운영 부담을 안겨줌. 하나의 애플리케이션 만을 위해서, 또는 작은 팀을 위해서 이를 운영하는 것은 편익이 작음. 대부분의 경우 설정 주입이 더 나은 선택.

## Transparency

> Transparency refers to the qualities that allow operators, developers, and business sponsors to gain understanding of the system’s historical trends, present conditions, instantaneous state, and future projections.

앞선 블랙 프라이데이 문제에서도, 이런 투명성이 없었다면 원인을 찾기 힘들었을 것. 투명한 시스템은 디버깅이 무척 쉽고, 따라서 그렇지 않은 시스템에 비해 빠르게 성숙할 수 있음. 믿을 수 있는 좋은 데이터가 없다면, 좋은 결정을 내리기도 어려움. 편견과, 정치적 영향력, 경영 스타일 등에 영향 받기 쉽상.

### DESIGNING FOR TRANSPARENCY

투명성은 의도적인 설계와 아키텍처 노력을 통해 가능함. 또한, 특정 어플리케이션이나 서버만의 투명성으로는 충분치 않음. 국소적 모니터링에 의한 최적화나 문제 해결은, 전체적으로는 효과가 없을 수도. 마찬가지로 특정 시점뿐만이 아니라 시계열 투명성이 필요. 의존성도 중요. 그러니까, 모니터링과 리포팅은 시스템의 내부가 아니라 외부에 위치해야 함. 이런 정책은 애플리케이션 코드가 변화하는 주기와 매우 다름.

### ENABLING TECHNOLOGIES

프로세스 경계의 불투명도를 낮추는 일을 가리킴. 정보를 바깥으로 끌어내는 일. 크게 화이트 박스 방식과, 블랙 박스 방식으로 분류.

### LOGGING

다양한 모니터링 도구들의 발전에도 불구하고 로그는 여전히 중요. 로깅은 소스 코드 상에서의 노력도 함께 요구되므로 화이트 박스 방식. 로그를 통해 애플리케이션의 행위에 대해 즉각적으로 알 수 있을 뿐만 아니라, 시스템의 상태도 함께 알 수 있음. 로그 파일만 있으면 다양한 도구와의 결합도 가능.

분명 가치 있는 로그이긴 하지만 가끔은 오용됨. 성공적인 로깅을 위한 몇 가지 요소들로 아래와 같은 것들이 있음.

#### Log Locations

로그 파일은 용량이 큼. 빠르게 자라나고, 많은 I/O를 사용. 물리 장비에서는 별도의 드라이브에 로그를 유지하는 것이 좋음. 장비가 더 많은 I/O 대역폭을 병렬로 사용하고, 드라이브의 경합을 줄일 수 있기도 하므로. 더불어, 여러가지 이유로 로그가 저장될 위치는 설정 가능한 것이 좋음. 

#### Logging Levels

"ERROR"나 "SEVERE"는 어떤 행위가 필요한 경우여야 함. 사용자가 잘못된 카드 번호를 입력하거나 하는 등의 유효성 검증에서는 "ERROR" 이상의 레벨로 로깅할 필요가 없음. 써킷 브레이커가 "open" 된 경우라면 에러 로깅이 의미가 있고, 이 때는 커넥션과 관련해서 어떤 조치를 취해야 함을 의미.

#### Human Factors

로그 파일은 결국 사람이 읽는 것. 읽는 사람에게 명확하고, 정확하며, 실행 가능한 정보를 전달해야 함.

#### Voodoo Operations

실제로는 패턴이 없는데도 패턴을 발견하려는 인간의 경향을 언급. 그리고 이로 인해 문제가 발생할 수 있음을 사례로 소개. 저자는 어느 애플리케이션을 개발할 때 디버깅 메시지로 “Data channel lifetime limit reached. Reset required.”를 남겼었다고 함. 그런데, 마침 이 메시지 직후 데이터베이스가 잠시 다운된 적이 있었음. 그 후로 몇 개월간 이 메시지가 보이면, 운영자는 디비를 페일 오버하고, 마스터 노드를 재시작해 왔다고 함. 하지만, 이 메시지의 의미는 외부 기관과 데이터를 주고 받음에 사용되는 암호화 키를 갱신해야 한다는 것이었고, 애플리케이션 스스로 이 일을 하게끔 했었다고 함. 단지 필자가 디버그를 위해 남긴 로그가 프로덕션에도 남았고, 의미가 모호하기 때문에, 그리고 마침 일어났던 디비 문제로, 매번 이 메시지가 보일 때마다 디비 재시작을 했던 것. 참고로, 이 메시지는 일주일에 한 번씩 로그로 남았다고 함.

#### Final Notes on Logging

메시지는 식별자를 가져야 함. 이 식별자는 트랜잭션의 단계를 추적하기 위한 값. 사용자의 ID, 세션 ID, 트랜잭션 ID 등이 식별자의 후보. 수 많은 로그 라인에서 필요한 데이터만 추출할 수 있게 도와줄 것.

흥미로운 상태 전이도 로깅되어야 함. JMS 알림이나 SNMP 트랩을 사용한다고 하더라도 말이다. 상태 전이를 로깅하는데 시간도 걸리고 약간의 부가적인 코드도 필요하지만, it leaves options open downstream. 게다가 포스트모텀에서 중요한 단서가 될 수도.

### INSTANCE METRICS

전체적인 시스템 건강에 대해 알기 위해서, 중앙에서 수집되고 분석되고 시각화 될 수 있도록 메트릭을 제공해 줘야 함.

### HEALTH CHECKS

메트릭 보다 좀 더 빠르게 상태를 파악하기 위해 헬스 체크 정보를 제공. 그리고 단지 "돌아가고 있어요"를 넘어, 아래와 같은 것들도 함께 제공.

1. 호스트 IP나 주소
2. 런타임 또는 인터프리터의 버전 (Ruby, Python, ...)
3. 어플리케이션 버전이나 커밋 ID
4. 인스턴스가 일을 받아주고 있는지 여부
5. 커넥션 풀, 캐시, 써킷 브레이커의 상태

헬스 체크는 트래픽 관리에서도 중요. 다음 장에서 살펴봄.

# Interconnect

Foundation, Instance에 대해 알아봤으니, [여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/design_for_production/layered_concerns.png)대로 Interconnect에 대해 다룰 차례. Routing, load balancing, failover, traffic management 등을 이야기. 높은 가용성을 만들어 내는 부분이기도 함.

## Solutions at Different Scales

Foundation, Instance 다루는 부분은 프로덕션 환경이 무엇이냐에 따라 선택이 달라지는 반면, Interconnect, Control Plane, Operation에서는 조직의 상황을 고려해야 함. 예컨대, 조직의 수가 많고 변화가 잦은 곳에서는 Consul 등의 동적 디스커버리 서비스가 이득이 되겠지만, 그렇지 않다면 DNS 엔트리를 고려하는 것도 괜찮음.

일례로, 디스커버리 서비스 사용의 편익을 따지는 이야기가 나옴. 변화가 얼마나 잦은가, 늘어나는 운영적 부담을 떠안을 조직은 있는가, 조직 규모가 커서 IP 주소와 같은 변경사항(가상화나 클라우드 환경에서는 자주 일어나는)을 모두 일일이 개발자가 대응해야 하지는 않는지.

## DNS

작은 팀에서는 DNS가 좋은 선택. 인프라가 천천히 변하는 경우라면 더더욱.

### SERVICE DISCOVERY WITH DNS

서비스 디스커버리는 일반적으로 자동화 된 질의와 응답을 가리키지만, 적어도 DNS로 다른 서비스를 찾을 때의 이야기는 아님. 서비스 소유자에게 DNS 이름을 알아내야 하며, 이렇게 휴먼 프로토콜이 끝난 뒤, 설정 파일에 호스트 명을 입력. 그러고는 잊어버림.

서비스 제공자가 호출자에게 1개의 DNS 이름을 알려줬다면, 로드 밸런싱과 고가용성은 제공자에게 책임이 있다는 의미. 여러 개의 이름을 제공한다면, 호출자에게 책임이 있음. 한편, 물리적 호스트 명. 대신, 논리적 서비스 이름을 사용하는 것이 중요. 별칭의 변경은 한 번에 한 곳에서 일어나야 함. 모든 소비 어플리케이션을 바꾸는 대신 말이다.

### LOAD BALANCING WITH DNS

DNS 라운드 로빈은 오래된 기법 중 하나. OSI 계층의 애플리케이션 계층이긴 하나, 서비스 요청이 일어나는 때가 아닌, 주소 리졸브 과정에서 일어나는 일. 다음은 이 방식의 한계들.

1. 호출자가 IP 주소를 알게 되고 직접 접근. 물론 방화벽이 있겠지만 말이다.
2. DNS는 인스턴스의 상태를 알 수 없음. 바쁘거나 심지어 다운된 인스턴스로도 라우팅이 됨.
3. 자바 빌트인 클래스 등에서 DNS 캐싱을 하므로, IP 변경이 제대로 반영되지 않을 수 있음.

### GLOBAL SERVER LOAD BALANCING WITH DNS

GSLB(Global Server Load Balancing)에서는 DNS가 유용하다고 함. [여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/design_for_production/gslb.png)을 보면 쉽게 이해할 수 있음. 지역적으로 가까운 인스턴스로 라우팅이 가능한 것. 그런데, 그림을 보면 알 수 있듯, 완전히 DNS로 구성된 것이 아니고, GSLB에 더해 로드 밸런서를 함께 구성한 것. DNS는 단지 특정 인스턴스 풀로 연결하기 위한 가상 IP 주소를 제공할 뿐임. 이외에도 상황에 맞는 다양한 변형들이 존재함.

### AVAILABILITY OF DNS

DNS의 정전은 큰 영향을 미칠 수 있음, 따라서, 프로덕션 시스템과 동일한 인프라에 호스팅하지 않아야 하며, 서로 다른 위치에 있는 2개 이상의 DNS 제공자를 사용할 것. 적어도 1개의 DNS 서버에만 문제가 있다면, 별다른 문제가 없어야 함.

## Load Balancing

오늘날 대부분은 수평적 확장이 가능. 가용량과 탄력성을 가져다주지만, 로드 밸런서가 필요. [여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/design_for_production/lb_and_vips.png)은 로드 밸런서 구성의 한 예. 

1. 모든 액티브 로드 밸런서는 1개 이상의 소켓을 1개 이상의 IP 주소에 대해 리스닝.
2. 이 IP 주소들은 흔히 VIP라고 불림.
3. 로드 밸런서의 단일 물리 네트워크 포트는 여러 VIP가 바운딩.
4. 각 VIP는 1개 이상의 "풀<sup>pool</sup>"에 매핑.

호출 애플리케이션은 로드 배런서가 있는지를 몰라야 함. 서비스 제공자는 자신의 호스트 대신 VIP의 DNS 이름을 URL 생성에 사용해야 함. 로드밸런서에는 소프트웨어와 하드웨어가 존재함.

### SOFTWARE LOAD BALANCING

저 비용 접근법. 기본적으로는 리버스 프록시 서버. DNS 라운드 로빈처럼, 리버스 프록시 서버는 이런 분산을 애플리케이션 레이어에서 수행. X-Fowrarded-For 헤더 이야기도 언급. 응답을 캐싱하기도. 이는 서비스 제공자의 부담을 줄여주는 일. 책에서는 HAProxy, Squid 보다는 Akamai를 추천. 모든 요청을 다 받아주기 때문에 금방 부담이 되기 쉬움. 리버스 프록시 서버 앞에 또 로드 밸런서를 고민한다면, 이제 다른 옵션을 생각해 볼 때.

### HARDWARE LOAD BALANCING

리버스 프록시보다 더 나은 가용량과 처리 속도를 보여줌. 다만 비용이 문제. 

### HEALTH CHECKS

로드 밸런서에서 중요한 것은 서비스 헬스 체크. 빈도와 실패 횟수 등으로 설정. 내용은 별 것 없음.

### STICKINESS

서로 다른 요청을 같은 인스턴스로 보내는 것. 상태가 있는 서비스에 필요. 이전 요청에 의해 리소스가 인스턴스 메모리에 올라가 있다면, 속도 면에서 유리할 수도. 다만, 분배가 제대로 되지 않을 수도. 핫 스팟. *stickiness*를 위해, 인스턴스를 식별할 수 있는 값을 해싱하여 첫 번째 요청 응답 쿠키에 넣어 둘 수도 있고, 요청 IP를 기준으로 같은 세션으로 간주할 수도. 당연히 한계도 존재.

### PARTITIONING REQUEST TYPES

컨텐츠 기반으로 라우팅. 예컨대, 검색 요청은 특정 인스턴스들로 라우팅, use-signup(?) 요청은 그 외 인스턴스들로 보내고.

## Demand Control

예전과 달리 사용자가 급작스럽게 늘어날 수 있음. 자연 보호는 없음. 거부하거나 스케일 아웃해야 함. 지금은 언제, 어디서, 어떻게 거부해야 하는지에 대해 이야기.

### HOW SYSTEMS FAIL

모든 실패하는 시스템은 어딘가에 백업된 큐와 함께 시작함.

요청/응답 작업을 생각할 땐, 소비되는 리소스와, 그 리소스에 접근하기 위한 큐를 함께 고려해야 함. 이는 새로운 요청을 차단할 지점을 결정하게 해줌. 각 요청은 요청이 지나는 티어 마다 소켓 하나를 소비. 아직 요청이 살아있다면, 새로운 요청을 할당할 소켓 하나가 부족하다는 것.

두 번째로 고려할 리소스는 NIC를 통한 저 수준의 I/O 대역. 얼마나 많은 가상 NIC를 가지고 있든, 인스턴스가 얼마나 많은 소켓을 열고 있든, 이더넷은 본질적으로 시리얼 프로토콜. 포트가 바쁘다면 어느 전송 패킷이든 줄을 서게 되고, 반대로 NIC를 통해 들어온 것들은 애플리케이션이 읽어 들이기 전까지 버퍼 상태. 전송과 수신 모두의 경우에 유한한 RAM이 이들 버퍼에 할당됨. 버퍼가 가득차면 데이터 쓰기와 읽기는 중단되고 연결과 호출은 차단됨.

### PREVENTING DISASTER

결국, 부하가 클 때 할 수 있는 가장 좋은 것은, 시간 내에 처리할 수 없는 요청을 거부하는 것. 앞서 *shed load*라 부르기도 했음. 느린 타임아웃 보다 빠른 거부가 낫다. 가장 경계에 있는 로드 밸런서가 적절한 위치. 서비스 부하가 심한 경우라면 로드 밸런서에게 이를 알려줄 수 있어야 하고, 모든 서비스가 이용 불가하다면 로드 밸런서는 HTTP 503 응답 코드를 내려줄 수 있어야 함. "too busy, try later." 일종의 *back pressure*.

리슨 큐는 상대적으로 짧아야 함. "residence time = listen queue + in processing". 프로세싱 시간 뿐 아니라, 리슨 큐에 머무르는 시간 또한 함께 측정되어야 함. 프로세싱은 멀티 스레드인 반면, 큐는 순차로 처리됨에도 유의. 리슨 큐 길이의 출발점으로 다음을 제안. `(최대 대기 시간 / 평균 처리 속도 + 1) * 요청 다루는 스레드 수 * 1.5` 왜지?

클라이언트는 TCP 연결을 재시도하기 때문에, 서비스가 수요를 따라갈 수 없을 때는, 리슨 큐를 비우는 것<sup>listen queue purge</sup>가 도움이 될 수 있다고 함.

## Network Routing

데이터 센터의 장비들은 보통 다수의 네트워크 인터페이스를 사용하기 때문에, 어떤 인터페이스로 데이터를 보내야 하는지 의문이 들 때가 있음. 예를 들어, 프론트엔드 네트워크 인터페이스는 A라는 VLAN에 연결 되어 웹 서버와 통신하고, 백엔드 네트워크 인터페이스는 B라는 VLAN에 연결되어 데이터베이스 서버와 통신함. 이 경우, 서버는 어떤 인터페이스를 사용할지 알아야 원하는 목적지 IP 주소와 통신할 수 있음.

인접한 서버들 간 통신은 쉬움. 서브넷을 공유하면 됨. 웹 서버와는 A VLAN의 서브넷을, 데이터베이스 서버와는 B VLAN의 서브넷을 말이다. 서드 파티 서비스 같은 거리가 있는 서비스와의 통신은 좀 더 복잡해짐. Gateway릍 통해 요청을 주고 받고, 포트 포워딩을 하는 등의 이야기인 듯. 로드 밸런서가 들어갈 수도 있고 등등.

현대의 OS는 라우팅을 자동으로, 그리고 보이지 않게 처리해 주지만, 이따금 문제가 됨. 예를 들어, 비즈니스 파트너스와 서비스를 통합했다고 해보자. 이 통합 지점에는 개인 식별 정보(PII)가 오고 가므로, 퍼블릭 인터넷이 아닌 VPN을 설정. 하지만, VPN과 기본 스위치<sup>primary switch</sup> 모두 비즈니스 파트너의 주소로 통신이 가능하다면?

한 가지 해결 방법은 정적 라우팅 정의. 네트워크 관리자가 분노할지 모르지만 때로는 유일한 수단. 또 다른 방법은 소프트웨어로 정의된 네트워킹. 가상화 또는 컨테이너 기반 인프라에서 유용. VIP, VLAN 태깅, 가상 스위치 등을 만들어 "네트워크 위에 네트워크"를 구성하는 것.

## Discovering Services

서비스 디스커버리가 의미 있는 경우는 2가지.

1. DNS 관리로는 감당하기 어려울 정도로 서비스가 많거나,
2. 환경이 꽤나 동적인 경우.

컨테이너 기반 환경에서는 이 2가지 모두에 해당. 또한, 다음의 특징을 가짐.

1. 서비스 스스로 요청을 받겠다고 공표하는 방식. 이는 정적으로 설정된 로드 밸런서 풀을 동적 풀로 바꾸는 것.
2. 두 번째는 룩업<sup>lookup</sup>. 호출자는 특정 서비스를 찾아가야 함.

서비스 디스커버리는 그 자체로 또 하나의 서비스. 장애도 날 수 있고, 부하가 걸릴 수도. 클라이언트에는 어느 정도 캐싱이 필요. 더불어, 직접 만들어서 사용하지 않기를 권장.

> Like connection pools and crypto libraries, there's a world of difference between writing one that works and writing one that always works.

분산 데이터 저장소인 ZooKeeper나 etcd를 서비스 디스커버리로 사용할 수 있음. 참고로, ZooKepper는 "CP"(CAP에서 A가 빠진) 시스템. 네트워크 파티션이 발생할 때, 일부 노드는 응답하지 않음. 따라서, 폴백으로 다른 노드를 사용하거나, 이미 캐싱된 결과를 사용하는 등의 클라이언트 처리가 필요. 한편, Consul은 "AP". 파티션이 발생할 때, 모두 가용하긴 하지만, 오래된 데이터가 제공될 수 있음. 더불어, 서비스 디스커버리에 더해 헬스 체크도 다룸.

다른 서비스 디스커버리 도구들은 PaaS 플랫폼의 *control plane*과 직접적으로 통합되어 있음. Docker Swarm은 컨테이너를 시작할 때, swarm의 동적 DNS와 로드 밸런싱 메커니즘에 컨테이너를 자동으로 등록함.

## Migratory Virtual IP Addresses

중요한 애플리케이션을 호스팅하는 서버가 죽었다고 가정해 보자. 자체적으로 클러스터링<sup>natively clustered</sup>은 되어 있지 않고 말이다. 페일오버 노드에 있는 클러스터 서버가 원래 서버가 죽은 것을 알고 보조 서버를 시작. 이 때, 클러스터 네트웍 인터페이스에 할당되어 있던 가상 IP 주소를 보조 서버가 인계 받음. 페일오버 전후의 모습은 [여기 그림](https://learning.oreilly.com/library/view/release-it-2nd/9781680504552/images/general_design_issues/virtual_ip_failover.png)과 같음.

이런 종류의 이동하는<sup>migratory</sup> IP 주소는 액티브/패시브 데이터베이스 클러스터에 주로 사용됨. 클라이언트는 VIP 주소를 위한 DNS 이름만을 사용하여 연결. 클러스터 노도의 호스트명 대신 말이다. 어떤 노드가 그 IP 주소를 가지고 있는지 여부와 상관 없이 오직 이름만을 이용해 연결하기 위함.

물론, 애플리케이션의 인 메모리 상태까지 마이그레이션하지는 못함. 이로 인해, 비영속적 상태는 유실됨. DB의 커밋되지 않은 트랜잭션이 한 예. Oracle JDBC나 ODBC 등의 일부 데이터베이스 드라이버는 페일오버로 인해 종료된 쿼리를 자동으로 재수행하기도 함. 업데이트, 인서트, 스토어드 프로시저 등은 반복될 수 X. 따라서, VIP를 통해 데이터베이스를 호출하는 모든 애플리케이션은 페일오버 등으로 인한 SQLException을 받을 준비가 되어 있어야 함. (하지만, 연결 누수 없이 요청을 실패 처리하는 것 말고 다른 준비가 가능한가?)

좀 더 일반화하면, VIP를 통해 다른 서비스를 호출하는 애플리케이션은, 다음 TCP 패킷이 마지막으로 보냈던 인터페이스와 다를 수 있음에 대비해야 함. 예상치 못한 지점에서 IOException이 발생할 수 있음. "destination unreachable" 에러와는 다르게 다뤄야 함. 가능하다면 애플리케이션은 새로운 노드로 요청을 재시도해야. (정말?)

# Control Plane

## How Much Is Right for You?

비용 측면을 강조. 일단 도입 시의 어려움(어느 하나만으로 되지도 않고, 이것 저것 꾸역 꾸역 통합해야 하며, ...), 운영의 부담, 지속적인 업데이트를 따라가야 하는 비용 등 여러가지를 함께 고려해야 함. 무작정 도입 X.

그래서 이 부분은 읽기 생략. 이 책을 읽는 목적과 부합 X.

# Security

보안의 중요성을 강조하고 있음. 이어지는 장에서는 OWASP(Open Web Application Security Project)라는 곳에서 만든 10가지 애플리케이션 취약점을 살펴보고, 데이터 보호와 무결성에 대해서도 이야기.

## The OWASP Top 10

논쟁의 여지가 있긴 하지만, 보안에 대해 걱정하는 것을 멈출 수 없음을 보여주는 목록이라고 함. 책 뒤로 갈수록 책에 대한 의구심이 자라나는 중. 하지만 평소 보안에 대해 꾸준히 공부하는 것은 아니니 다시 한 번 되살펴 보자는 의미로 한 번 기록해 보기로 함.

### INJECTION

SQL 인젝션과 XML 인젝션에 대해 설명. XML 인젝션의 한 예는 아래와 같음.

```xml
<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE foo [
<!ELEMENT foo ANY >
<!ENTITY xxe SYSTEM "file:///etc/passwd" >]><foo>&xxe;</foo>
```

대부분의 XML 파서들은 기본적으로 XXE 인젝션에 취약하다고 함. 그렇다고, XML 파서를 직접 만들라는 이야기는 아님. 별도의 XML 파서 설정이 필요할 뿐. SQL injection, XXE 외에도 Format 문자열 공격, "Eval 인젝션", XPATH 인젝션 등 다양함.

### BROKEN AUTHENTICATION AND SESSION MANAGEMENT

인증과 세션 관리에는 여러 가지 문제들이 존재. 세션 ID를 URL에 포함시키는 것처럼 명확할 수도, 솔트<sup>salt</sup>되지 않은 비밀번호를 데이터베이스에 그냥 저장하는 것처럼 눈에 드러나지 않을 수도.

먼저, "session hijacking".

1. 한 때는 URL 또는 쿼리 파라미터에 세션 ID를 넣었다고 함.
2. 한 번은 마케터의 세션 ID가 담긴 채로 마케팅 메일이 발송되고, 수 많은 클릭이 이 세션을 독점하려는 시도로 인해, 대규모 장애가 발생하기도 했다고.
3. 쿠키 형태로 세션 ID로 저장된 경우에도 XSS 공격을 통해 문제가 될 수 있음.

"session fixation" 문제도 함께 언급. [여기](https://www.owasp.org/index.php/Session_fixation)에 사례와 함께 설명이 잘 되어 있음. "session prediction" 공격 문제도 이야기. OWASP는 세션 ID를 다루는 데 있어 다음의 가이드라인을 제시.

1. 많은 불확실성<sup>entropy</sup>이 담긴 긴 세션 ID를 사용.
2. PRNG(pseudorandom number generator)를 사용해 세션 ID를 생성. 언어에 내장된 rand 함수는 아닐 것.
3. XSS 방어. 노출된 세션 ID로 스크립트가 실행되는 것을 막는 것.
4. 사용자가 인증할 때 신선한 세션 ID를 사용. session fixation 공격이 일어나도, 공격자는 사용자의 계정에 접근할 수 없을 것. (아하!)
5. 플랫폼에 내장된 세션 관리 기능들을 사용. 이미 많은 공격들에 대비하여 만들어진 것. 다만, 패치나 버전을 잘 따라갈 것.
6. 세션 ID를 쿠키를 통해서만 교환할 것. 어떤 시스템들은 여전히 쿠키는 물론 쿼리 파라미터를 통해서도 세션 ID를 받아주고 있음.

다음은 민감 정보<sup>credentials</sup>. 가장 간단한 문제는 HTTPS 등의 보호 없이 그냥 데이터를 주고 받는다는 것. 다음은 민감 정보 관련한 몇 가지 가이드.

1. 페스워드를 데이터베이스에 저장하지 말라.
2. "잃어버린 패스워드" 프로세스에서 사용자에게 패스워드를 이메일로 전송하지 말라.
3. 강한 해시 알고리즘을 패스워드에 적용하라. 딕셔너리 공격을 어렵게 만들기 위해 솔트<sup>salt</sup>를 사용.
4. 사용자에게 긴 비밀번호를 사용하게끔 하라.
5. 비밀번호를 다시 해싱할 계획을 세워라. 해시 알고리즘을 계속 강하게 유지해야 하고, 솔트 역시 바꿔줘야 함.
6. 제한 없이 인증 시도하는 것을 막아라.

### CROSS-SITE-SCRIPTING

생략

### BROKEN ACCESS CONTROL

